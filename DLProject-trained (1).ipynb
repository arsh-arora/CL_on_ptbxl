{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 03:25:37.447654: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733176537.468291 3993000 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733176537.474697 3993000 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-03 03:25:37.497775: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "import time\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data from dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3'\n",
    "\n",
    "ptbxl_df = pd.read_csv(os.path.join(DATA_PATH, 'ptbxl_database.csv'))\n",
    "scp_statements = pd.read_csv(os.path.join(DATA_PATH, 'scp_statements.csv'), index_col=0)\n",
    "\n",
    "diagnostic_scps = scp_statements[scp_statements['diagnostic'] == 1].index.values\n",
    "\n",
    "scp_to_superclass = scp_statements['diagnostic_class'].to_dict()\n",
    "scp_to_subclass = scp_statements['diagnostic_subclass'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df['scp_codes'] = ptbxl_df['scp_codes'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_diagnostic_labels(df, scp_codes, scp_to_agg):\n",
    "    df = df.copy()\n",
    "    def aggregate_labels(scp_codes_dict):\n",
    "        labels = set()\n",
    "        for code in scp_codes_dict.keys():\n",
    "            if code in scp_codes:\n",
    "                label = scp_to_agg.get(code)\n",
    "                if label:\n",
    "                    labels.add(label)\n",
    "        return list(labels)\n",
    "    df['diagnostic_labels'] = df['scp_codes'].apply(aggregate_labels)\n",
    "    return df\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_superclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'superclass_labels'})\n",
    "\n",
    "ptbxl_df = aggregate_diagnostic_labels(ptbxl_df, diagnostic_scps, scp_to_subclass)\n",
    "ptbxl_df = ptbxl_df.rename(columns={'diagnostic_labels': 'subclass_labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbxl_df = ptbxl_df[ptbxl_df['superclass_labels'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ptbxl_df[ptbxl_df.strat_fold <= 8]\n",
    "val_df = ptbxl_df[ptbxl_df.strat_fold == 9]\n",
    "test_df = ptbxl_df[ptbxl_df.strat_fold == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, sampling_rate, data_path):\n",
    "    data = []\n",
    "    i = 0\n",
    "    if sampling_rate == 100:\n",
    "        filenames = df['filename_lr'].values\n",
    "    else:\n",
    "        filenames = df['filename_hr'].values\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(data_path, filename)\n",
    "        signals, _ = wfdb.rdsamp(file_path)\n",
    "        data.append(signals)\n",
    "    return np.array(data)\n",
    "\n",
    "X_train = load_data(train_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_val = load_data(val_df, sampling_rate=100, data_path=DATA_PATH)\n",
    "X_test = load_data(test_df, sampling_rate=100, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_super = train_df['superclass_labels'].values\n",
    "val_labels_super = val_df['superclass_labels'].values\n",
    "test_labels_super = test_df['superclass_labels'].values\n",
    "\n",
    "mlb_super = MultiLabelBinarizer()\n",
    "y_train_super = mlb_super.fit_transform(train_labels_super)\n",
    "y_val_super = mlb_super.transform(val_labels_super)\n",
    "y_test_super = mlb_super.transform(test_labels_super)\n",
    "classes_super = mlb_super.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_sub = train_df['subclass_labels'].values\n",
    "val_labels_sub = val_df['subclass_labels'].values\n",
    "test_labels_sub = test_df['subclass_labels'].values\n",
    "\n",
    "mlb_sub = MultiLabelBinarizer()\n",
    "y_train_sub = mlb_sub.fit_transform(train_labels_sub)\n",
    "y_val_sub = mlb_sub.transform(val_labels_sub)\n",
    "y_test_sub = mlb_sub.transform(test_labels_sub)\n",
    "classes_sub = mlb_sub.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_per_channel(X):\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    mean = np.mean(X, axis=(0, 2), keepdims=True)\n",
    "    std = np.std(X, axis=(0, 2), keepdims=True)\n",
    "    X = (X - mean) / std\n",
    "    X = np.transpose(X, (0, 2, 1))\n",
    "    return X\n",
    "\n",
    "X_train = normalize_data_per_channel(X_train)\n",
    "X_val = normalize_data_per_channel(X_val)\n",
    "X_test = normalize_data_per_channel(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts_super = np.sum(y_train_super, axis=0)\n",
    "total_samples_super = y_train_super.shape[0]\n",
    "\n",
    "class_weight_super = {}\n",
    "for i, count in enumerate(class_counts_super):\n",
    "    class_weight_super[i] = total_samples_super / (len(class_counts_super) * count)\n",
    "\n",
    "class_counts_sub = np.sum(y_train_sub, axis=0)\n",
    "total_samples_sub = y_train_sub.shape[0]\n",
    "\n",
    "class_weight_sub = {}\n",
    "for i, count in enumerate(class_counts_sub):\n",
    "    class_weight_sub[i] = total_samples_sub / (len(class_counts_sub) * count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_super = y_train_super.shape[1]\n",
    "class_totals = np.sum(y_train_super, axis=0)\n",
    "class_weights = class_totals.max() / class_totals\n",
    "weights_array = np.array(class_weights, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "class_totals_sub = np.sum(y_train_sub, axis=0)\n",
    "class_weights_sub = class_totals_sub.max() / class_totals_sub\n",
    "weights_array_sub = np.array(class_weights_sub, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_super = y_train_super.astype(np.float32)\n",
    "y_val_super = y_val_super.astype(np.float32)\n",
    "y_test_super = y_test_super.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Entropy and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_binary_crossentropy(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        weights_cast = K.cast(weights, y_pred.dtype)\n",
    "        y_true = K.cast(y_true, y_pred.dtype)\n",
    "        \n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * weights_cast + (1 - y_true)\n",
    "        weighted_bce = weight_vector * bce\n",
    "        return K.mean(weighted_bce)\n",
    "    return loss\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred = K.round(y_pred)\n",
    "    \n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(y_true * y_pred, axis=0)\n",
    "    fp = K.sum((1 - y_true) * y_pred, axis=0)\n",
    "    fn = K.sum(y_true * (1 - y_pred), axis=0)\n",
    "    support = K.sum(y_true, axis=0)\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    weighted_f1 = K.sum(f1 * support) / K.sum(support)\n",
    "    weighted_f1 = tf.where(tf.math.is_nan(weighted_f1), 0.0, weighted_f1)\n",
    "    \n",
    "    return weighted_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv1D(64, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(128, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(256, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv1D(512, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_resnet_model(input_shape, num_classes):\n",
    "#     inputs = layers.Input(shape=input_shape)\n",
    "#     x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Activation('relu')(x)\n",
    "#     x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "#     previous_filters = x.shape[-1]\n",
    "#     for filters in [64, 128, 256]:\n",
    "#         x_shortcut = x\n",
    "#         strides = 1\n",
    "#         if previous_filters != filters:\n",
    "#             strides = 2\n",
    "\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, strides=strides, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         x = layers.Conv1D(filters, kernel_size=3, padding='same')(x)\n",
    "#         x = layers.BatchNormalization()(x)\n",
    "        \n",
    "#         if previous_filters != filters or strides != 1:\n",
    "#             x_shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(x_shortcut)\n",
    "#             x_shortcut = layers.BatchNormalization()(x_shortcut)\n",
    "        \n",
    "#         x = layers.Add()([x, x_shortcut])\n",
    "#         x = layers.Activation('relu')(x)\n",
    "#         previous_filters = filters\n",
    "#     x = layers.GlobalAveragePooling1D()(x)\n",
    "#     outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "#     model = models.Model(inputs, outputs)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block_1d(x, filters, kernel_size=3, strides=1, downsample=False):\n",
    "    shortcut = x\n",
    "    \n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv1D(filters, kernel_size=kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if downsample or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv1D(filters, kernel_size=1, strides=strides, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=3, strides=2, padding='same')(x)\n",
    "    layers_filters = [64, 128, 256, 512]\n",
    "    layers_blocks = [3, 4, 6, 3]\n",
    "\n",
    "    for filters, num_blocks in zip(layers_filters, layers_blocks):\n",
    "        for i in range(num_blocks):\n",
    "            if i == 0 and filters != x.shape[-1]:\n",
    "                x = residual_block_1d(x, filters, strides=2, downsample=True)\n",
    "            else:\n",
    "                x = residual_block_1d(x, filters)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def create_vit_model(input_shape, num_classes):\n",
    "    patch_size = 10 \n",
    "    num_patches = input_shape[0] // patch_size\n",
    "    projection_dim = 64\n",
    "    num_heads = 4\n",
    "    transformer_layers = 8\n",
    "    mlp_head_units = [256, 128]\n",
    "    dropout_rate = 0.1\n",
    "\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Reshape((num_patches, patch_size * input_shape[1]))(inputs)\n",
    "    x = layers.Dense(units=projection_dim)(x)\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
    "    x = x + position_embedding(positions)\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=dropout_rate\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, hidden_units=[projection_dim * 2, projection_dim], dropout_rate=dropout_rate)\n",
    "        x = layers.Add()([x3, x2])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, class_weight, batch_size=64, epochs=25):\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', macro_f1, weighted_f1]\n",
    "    )\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Models without CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733176603.616395 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 31141 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.617574 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 31141 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.618481 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 31141 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.619354 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 31141 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.620257 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 31141 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:85:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.621177 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 31141 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:86:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.622083 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 31141 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "I0000 00:00:1733176603.622961 3993000 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 31141 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733176610.181785 3993651 service.cc:148] XLA service 0x7fe1fc03ded0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733176610.181822 3993651 service.cc:156]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181843 3993651 service.cc:156]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181848 3993651 service.cc:156]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181850 3993651 service.cc:156]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181869 3993651 service.cc:156]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181872 3993651 service.cc:156]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181876 3993651 service.cc:156]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "I0000 00:00:1733176610.181894 3993651 service.cc:156]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-12-03 03:26:50.293227: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733176610.732389 3993651 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 10/267\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.3684 - loss: 0.4607 - macro_f1: 0.4481 - weighted_f1: 0.4830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733176614.954350 3993651 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m265/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5982 - loss: 0.3098 - macro_f1: 0.6185 - weighted_f1: 0.6538"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1733176620.712555 3993649 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1733176621.006032 3993649 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.5987 - loss: 0.3094 - macro_f1: 0.6190 - weighted_f1: 0.6543 - val_accuracy: 0.6654 - val_loss: 0.3301 - val_macro_f1: 0.6820 - val_weighted_f1: 0.7177 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6832 - loss: 0.2411 - macro_f1: 0.7032 - weighted_f1: 0.7390 - val_accuracy: 0.6566 - val_loss: 0.3517 - val_macro_f1: 0.6529 - val_weighted_f1: 0.6995 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7026 - loss: 0.2278 - macro_f1: 0.7340 - weighted_f1: 0.7645 - val_accuracy: 0.6719 - val_loss: 0.3504 - val_macro_f1: 0.6656 - val_weighted_f1: 0.7078 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7086 - loss: 0.2125 - macro_f1: 0.7474 - weighted_f1: 0.7775 - val_accuracy: 0.6612 - val_loss: 0.3299 - val_macro_f1: 0.6884 - val_weighted_f1: 0.7271 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7214 - loss: 0.2064 - macro_f1: 0.7520 - weighted_f1: 0.7840 - val_accuracy: 0.6855 - val_loss: 0.2915 - val_macro_f1: 0.7165 - val_weighted_f1: 0.7567 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7246 - loss: 0.1999 - macro_f1: 0.7660 - weighted_f1: 0.7955 - val_accuracy: 0.6897 - val_loss: 0.3160 - val_macro_f1: 0.7225 - val_weighted_f1: 0.7577 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7392 - loss: 0.1904 - macro_f1: 0.7772 - weighted_f1: 0.8046 - val_accuracy: 0.7064 - val_loss: 0.2985 - val_macro_f1: 0.7086 - val_weighted_f1: 0.7495 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7343 - loss: 0.1871 - macro_f1: 0.7779 - weighted_f1: 0.8057 - val_accuracy: 0.6911 - val_loss: 0.3111 - val_macro_f1: 0.7139 - val_weighted_f1: 0.7564 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7433 - loss: 0.1799 - macro_f1: 0.7880 - weighted_f1: 0.8145 - val_accuracy: 0.7167 - val_loss: 0.2789 - val_macro_f1: 0.7292 - val_weighted_f1: 0.7678 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7490 - loss: 0.1751 - macro_f1: 0.7969 - weighted_f1: 0.8224 - val_accuracy: 0.7060 - val_loss: 0.2830 - val_macro_f1: 0.7262 - val_weighted_f1: 0.7673 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7564 - loss: 0.1667 - macro_f1: 0.8021 - weighted_f1: 0.8289 - val_accuracy: 0.6966 - val_loss: 0.3012 - val_macro_f1: 0.7196 - val_weighted_f1: 0.7592 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7574 - loss: 0.1630 - macro_f1: 0.8084 - weighted_f1: 0.8331 - val_accuracy: 0.6911 - val_loss: 0.2947 - val_macro_f1: 0.7209 - val_weighted_f1: 0.7663 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7683 - loss: 0.1517 - macro_f1: 0.8232 - weighted_f1: 0.8454 - val_accuracy: 0.7120 - val_loss: 0.3006 - val_macro_f1: 0.7062 - val_weighted_f1: 0.7524 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7743 - loss: 0.1468 - macro_f1: 0.8269 - weighted_f1: 0.8501 - val_accuracy: 0.7046 - val_loss: 0.3086 - val_macro_f1: 0.7211 - val_weighted_f1: 0.7667 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7867 - loss: 0.1264 - macro_f1: 0.8560 - weighted_f1: 0.8736 - val_accuracy: 0.7060 - val_loss: 0.2938 - val_macro_f1: 0.7164 - val_weighted_f1: 0.7648 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8064 - loss: 0.1056 - macro_f1: 0.8816 - weighted_f1: 0.8949 - val_accuracy: 0.7018 - val_loss: 0.3034 - val_macro_f1: 0.7283 - val_weighted_f1: 0.7711 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8055 - loss: 0.1012 - macro_f1: 0.8866 - weighted_f1: 0.9001 - val_accuracy: 0.7060 - val_loss: 0.3117 - val_macro_f1: 0.7141 - val_weighted_f1: 0.7620 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8138 - loss: 0.0937 - macro_f1: 0.8947 - weighted_f1: 0.9063 - val_accuracy: 0.7032 - val_loss: 0.3204 - val_macro_f1: 0.7149 - val_weighted_f1: 0.7619 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.8129 - loss: 0.0920 - macro_f1: 0.8949 - weighted_f1: 0.9085 - val_accuracy: 0.6994 - val_loss: 0.3276 - val_macro_f1: 0.7197 - val_weighted_f1: 0.7648 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe6bba34910>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "num_classes_super = y_train_super.shape[1]\n",
    "\n",
    "cnn_super_model = create_cnn_model(input_shape, num_classes_super)\n",
    "train_model(cnn_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m265/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5538 - loss: 0.3813 - macro_f1: 0.5263 - weighted_f1: 0.5638"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1733176763.685155 3993646 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1733176763.913225 3993646 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.5545 - loss: 0.3805 - macro_f1: 0.5273 - weighted_f1: 0.5647 - val_accuracy: 0.4744 - val_loss: 0.5546 - val_macro_f1: 0.5420 - val_weighted_f1: 0.5600 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.6738 - loss: 0.2569 - macro_f1: 0.6835 - weighted_f1: 0.7178 - val_accuracy: 0.5955 - val_loss: 0.4619 - val_macro_f1: 0.5937 - val_weighted_f1: 0.6360 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6900 - loss: 0.2465 - macro_f1: 0.7079 - weighted_f1: 0.7365 - val_accuracy: 0.6314 - val_loss: 0.3758 - val_macro_f1: 0.6524 - val_weighted_f1: 0.6813 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7050 - loss: 0.2326 - macro_f1: 0.7208 - weighted_f1: 0.7570 - val_accuracy: 0.6869 - val_loss: 0.2933 - val_macro_f1: 0.7029 - val_weighted_f1: 0.7528 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7037 - loss: 0.2207 - macro_f1: 0.7401 - weighted_f1: 0.7695 - val_accuracy: 0.7130 - val_loss: 0.3258 - val_macro_f1: 0.6822 - val_weighted_f1: 0.7333 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7123 - loss: 0.2125 - macro_f1: 0.7427 - weighted_f1: 0.7765 - val_accuracy: 0.6370 - val_loss: 0.3545 - val_macro_f1: 0.6713 - val_weighted_f1: 0.7119 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7242 - loss: 0.2078 - macro_f1: 0.7516 - weighted_f1: 0.7828 - val_accuracy: 0.6705 - val_loss: 0.3154 - val_macro_f1: 0.7047 - val_weighted_f1: 0.7466 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7185 - loss: 0.2071 - macro_f1: 0.7535 - weighted_f1: 0.7825 - val_accuracy: 0.6738 - val_loss: 0.3107 - val_macro_f1: 0.7159 - val_weighted_f1: 0.7529 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7358 - loss: 0.1976 - macro_f1: 0.7626 - weighted_f1: 0.7966 - val_accuracy: 0.5601 - val_loss: 0.4221 - val_macro_f1: 0.6319 - val_weighted_f1: 0.6558 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7441 - loss: 0.1856 - macro_f1: 0.7782 - weighted_f1: 0.8090 - val_accuracy: 0.6990 - val_loss: 0.2725 - val_macro_f1: 0.7153 - val_weighted_f1: 0.7652 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.7650 - loss: 0.1700 - macro_f1: 0.7956 - weighted_f1: 0.8261 - val_accuracy: 0.7046 - val_loss: 0.2757 - val_macro_f1: 0.7237 - val_weighted_f1: 0.7697 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7731 - loss: 0.1563 - macro_f1: 0.8162 - weighted_f1: 0.8426 - val_accuracy: 0.7083 - val_loss: 0.2817 - val_macro_f1: 0.7275 - val_weighted_f1: 0.7722 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7724 - loss: 0.1538 - macro_f1: 0.8231 - weighted_f1: 0.8483 - val_accuracy: 0.7008 - val_loss: 0.2805 - val_macro_f1: 0.7172 - val_weighted_f1: 0.7634 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7774 - loss: 0.1435 - macro_f1: 0.8321 - weighted_f1: 0.8552 - val_accuracy: 0.7018 - val_loss: 0.2983 - val_macro_f1: 0.7133 - val_weighted_f1: 0.7610 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7872 - loss: 0.1371 - macro_f1: 0.8390 - weighted_f1: 0.8612 - val_accuracy: 0.6869 - val_loss: 0.3084 - val_macro_f1: 0.7130 - val_weighted_f1: 0.7600 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.7896 - loss: 0.1239 - macro_f1: 0.8588 - weighted_f1: 0.8782 - val_accuracy: 0.7018 - val_loss: 0.3101 - val_macro_f1: 0.7164 - val_weighted_f1: 0.7619 - learning_rate: 1.0000e-05\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.7958 - loss: 0.1195 - macro_f1: 0.8600 - weighted_f1: 0.8804 - val_accuracy: 0.6971 - val_loss: 0.3230 - val_macro_f1: 0.7126 - val_weighted_f1: 0.7592 - learning_rate: 1.0000e-05\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.8007 - loss: 0.1163 - macro_f1: 0.8654 - weighted_f1: 0.8844 - val_accuracy: 0.6966 - val_loss: 0.3337 - val_macro_f1: 0.7140 - val_weighted_f1: 0.7606 - learning_rate: 1.0000e-05\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.8058 - loss: 0.1110 - macro_f1: 0.8691 - weighted_f1: 0.8893 - val_accuracy: 0.6938 - val_loss: 0.3383 - val_macro_f1: 0.7112 - val_weighted_f1: 0.7581 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.8012 - loss: 0.1112 - macro_f1: 0.8718 - weighted_f1: 0.8892 - val_accuracy: 0.6934 - val_loss: 0.3487 - val_macro_f1: 0.7122 - val_weighted_f1: 0.7587 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe54033e640>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_super_model = create_resnet_model(input_shape, num_classes_super)\n",
    "train_model(resnet_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 118ms/step - accuracy: 0.4160 - loss: 0.4427 - macro_f1: 0.4026 - weighted_f1: 0.4400 - val_accuracy: 0.5857 - val_loss: 0.3888 - val_macro_f1: 0.5262 - val_weighted_f1: 0.6025 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6201 - loss: 0.2971 - macro_f1: 0.6167 - weighted_f1: 0.6531 - val_accuracy: 0.6617 - val_loss: 0.3411 - val_macro_f1: 0.6518 - val_weighted_f1: 0.6993 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6700 - loss: 0.2532 - macro_f1: 0.6917 - weighted_f1: 0.7188 - val_accuracy: 0.6193 - val_loss: 0.3404 - val_macro_f1: 0.6591 - val_weighted_f1: 0.7015 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6949 - loss: 0.2336 - macro_f1: 0.7176 - weighted_f1: 0.7494 - val_accuracy: 0.6263 - val_loss: 0.3462 - val_macro_f1: 0.6644 - val_weighted_f1: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7129 - loss: 0.2127 - macro_f1: 0.7472 - weighted_f1: 0.7738 - val_accuracy: 0.6468 - val_loss: 0.3370 - val_macro_f1: 0.6541 - val_weighted_f1: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7210 - loss: 0.1996 - macro_f1: 0.7571 - weighted_f1: 0.7865 - val_accuracy: 0.6719 - val_loss: 0.3296 - val_macro_f1: 0.6831 - val_weighted_f1: 0.7275 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7374 - loss: 0.1825 - macro_f1: 0.7815 - weighted_f1: 0.8057 - val_accuracy: 0.6538 - val_loss: 0.3667 - val_macro_f1: 0.6781 - val_weighted_f1: 0.7242 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7532 - loss: 0.1705 - macro_f1: 0.7982 - weighted_f1: 0.8208 - val_accuracy: 0.6552 - val_loss: 0.3612 - val_macro_f1: 0.6646 - val_weighted_f1: 0.7121 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7541 - loss: 0.1600 - macro_f1: 0.8136 - weighted_f1: 0.8333 - val_accuracy: 0.6645 - val_loss: 0.3739 - val_macro_f1: 0.6722 - val_weighted_f1: 0.7212 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7683 - loss: 0.1479 - macro_f1: 0.8277 - weighted_f1: 0.8446 - val_accuracy: 0.6612 - val_loss: 0.3821 - val_macro_f1: 0.6635 - val_weighted_f1: 0.7057 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7758 - loss: 0.1350 - macro_f1: 0.8437 - weighted_f1: 0.8585 - val_accuracy: 0.6514 - val_loss: 0.3986 - val_macro_f1: 0.6650 - val_weighted_f1: 0.7146 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8116 - loss: 0.1039 - macro_f1: 0.8868 - weighted_f1: 0.8976 - val_accuracy: 0.6603 - val_loss: 0.4436 - val_macro_f1: 0.6712 - val_weighted_f1: 0.7206 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8171 - loss: 0.0835 - macro_f1: 0.9087 - weighted_f1: 0.9156 - val_accuracy: 0.6556 - val_loss: 0.4634 - val_macro_f1: 0.6741 - val_weighted_f1: 0.7210 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8277 - loss: 0.0765 - macro_f1: 0.9182 - weighted_f1: 0.9246 - val_accuracy: 0.6603 - val_loss: 0.4766 - val_macro_f1: 0.6709 - val_weighted_f1: 0.7196 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8377 - loss: 0.0696 - macro_f1: 0.9243 - weighted_f1: 0.9296 - val_accuracy: 0.6603 - val_loss: 0.4949 - val_macro_f1: 0.6711 - val_weighted_f1: 0.7200 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.8316 - loss: 0.0664 - macro_f1: 0.9275 - weighted_f1: 0.9341 - val_accuracy: 0.6608 - val_loss: 0.5158 - val_macro_f1: 0.6717 - val_weighted_f1: 0.7199 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe4900da280>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_super_model = create_vit_model(input_shape, num_classes_super)\n",
    "train_model(vit_super_model, X_train, y_train_super, X_val, y_val_super, class_weight_super)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.3719 - loss: 0.1269 - macro_f1: 0.0936 - weighted_f1: 0.2058 - val_accuracy: 0.4804 - val_loss: 0.1469 - val_macro_f1: 0.1673 - val_weighted_f1: 0.3670 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4881 - loss: 0.0759 - macro_f1: 0.2070 - weighted_f1: 0.3929 - val_accuracy: 0.4832 - val_loss: 0.1427 - val_macro_f1: 0.1630 - val_weighted_f1: 0.3839 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5141 - loss: 0.0717 - macro_f1: 0.2357 - weighted_f1: 0.4345 - val_accuracy: 0.4338 - val_loss: 0.1518 - val_macro_f1: 0.1888 - val_weighted_f1: 0.3482 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.5146 - loss: 0.0729 - macro_f1: 0.2523 - weighted_f1: 0.4636 - val_accuracy: 0.5224 - val_loss: 0.1274 - val_macro_f1: 0.2493 - val_weighted_f1: 0.4967 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5355 - loss: 0.0633 - macro_f1: 0.2848 - weighted_f1: 0.5140 - val_accuracy: 0.5116 - val_loss: 0.1330 - val_macro_f1: 0.2358 - val_weighted_f1: 0.4361 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5499 - loss: 0.0579 - macro_f1: 0.3001 - weighted_f1: 0.5350 - val_accuracy: 0.5811 - val_loss: 0.1128 - val_macro_f1: 0.2804 - val_weighted_f1: 0.5478 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5699 - loss: 0.0551 - macro_f1: 0.3245 - weighted_f1: 0.5646 - val_accuracy: 0.5098 - val_loss: 0.1265 - val_macro_f1: 0.2681 - val_weighted_f1: 0.5293 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5627 - loss: 0.0556 - macro_f1: 0.3307 - weighted_f1: 0.5653 - val_accuracy: 0.4422 - val_loss: 0.1370 - val_macro_f1: 0.2509 - val_weighted_f1: 0.4367 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5805 - loss: 0.0511 - macro_f1: 0.3515 - weighted_f1: 0.5929 - val_accuracy: 0.5718 - val_loss: 0.1211 - val_macro_f1: 0.3071 - val_weighted_f1: 0.5867 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5922 - loss: 0.0494 - macro_f1: 0.3599 - weighted_f1: 0.6136 - val_accuracy: 0.5107 - val_loss: 0.1255 - val_macro_f1: 0.2752 - val_weighted_f1: 0.5275 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5992 - loss: 0.0495 - macro_f1: 0.3606 - weighted_f1: 0.6152 - val_accuracy: 0.5429 - val_loss: 0.1175 - val_macro_f1: 0.2987 - val_weighted_f1: 0.5679 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6110 - loss: 0.0430 - macro_f1: 0.3961 - weighted_f1: 0.6453 - val_accuracy: 0.6067 - val_loss: 0.1050 - val_macro_f1: 0.3247 - val_weighted_f1: 0.6125 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6246 - loss: 0.0389 - macro_f1: 0.4034 - weighted_f1: 0.6624 - val_accuracy: 0.6174 - val_loss: 0.1033 - val_macro_f1: 0.3225 - val_weighted_f1: 0.6192 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6307 - loss: 0.0377 - macro_f1: 0.4118 - weighted_f1: 0.6700 - val_accuracy: 0.6137 - val_loss: 0.1039 - val_macro_f1: 0.3192 - val_weighted_f1: 0.6178 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6407 - loss: 0.0374 - macro_f1: 0.4187 - weighted_f1: 0.6813 - val_accuracy: 0.6114 - val_loss: 0.1039 - val_macro_f1: 0.3238 - val_weighted_f1: 0.6200 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6455 - loss: 0.0363 - macro_f1: 0.4349 - weighted_f1: 0.6867 - val_accuracy: 0.6184 - val_loss: 0.1051 - val_macro_f1: 0.3262 - val_weighted_f1: 0.6238 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6513 - loss: 0.0356 - macro_f1: 0.4186 - weighted_f1: 0.6867 - val_accuracy: 0.6160 - val_loss: 0.1040 - val_macro_f1: 0.3241 - val_weighted_f1: 0.6261 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6511 - loss: 0.0345 - macro_f1: 0.4401 - weighted_f1: 0.6982 - val_accuracy: 0.6114 - val_loss: 0.1064 - val_macro_f1: 0.3296 - val_weighted_f1: 0.6277 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6493 - loss: 0.0346 - macro_f1: 0.4354 - weighted_f1: 0.6999 - val_accuracy: 0.6174 - val_loss: 0.1047 - val_macro_f1: 0.3324 - val_weighted_f1: 0.6305 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6585 - loss: 0.0337 - macro_f1: 0.4371 - weighted_f1: 0.7056 - val_accuracy: 0.6142 - val_loss: 0.1045 - val_macro_f1: 0.3297 - val_weighted_f1: 0.6273 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6594 - loss: 0.0339 - macro_f1: 0.4366 - weighted_f1: 0.6935 - val_accuracy: 0.6188 - val_loss: 0.1044 - val_macro_f1: 0.3317 - val_weighted_f1: 0.6299 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6607 - loss: 0.0327 - macro_f1: 0.4365 - weighted_f1: 0.7073 - val_accuracy: 0.6193 - val_loss: 0.1043 - val_macro_f1: 0.3323 - val_weighted_f1: 0.6316 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6544 - loss: 0.0336 - macro_f1: 0.4444 - weighted_f1: 0.7034 - val_accuracy: 0.6188 - val_loss: 0.1047 - val_macro_f1: 0.3307 - val_weighted_f1: 0.6322 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe3482446a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "cnn_sub_model = create_cnn_model(input_shape, num_classes_sub)\n",
    "train_model(cnn_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 92ms/step - accuracy: 0.2457 - loss: 0.1394 - macro_f1: 0.0542 - weighted_f1: 0.0637 - val_accuracy: 0.1058 - val_loss: 0.2291 - val_macro_f1: 0.1014 - val_weighted_f1: 0.1006 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.3928 - loss: 0.1108 - macro_f1: 0.0942 - weighted_f1: 0.1543 - val_accuracy: 0.3453 - val_loss: 0.2005 - val_macro_f1: 0.0238 - val_weighted_f1: 0.0315 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4294 - loss: 0.0975 - macro_f1: 0.1229 - weighted_f1: 0.2275 - val_accuracy: 0.4497 - val_loss: 0.1600 - val_macro_f1: 0.1370 - val_weighted_f1: 0.3259 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4540 - loss: 0.0895 - macro_f1: 0.1589 - weighted_f1: 0.2893 - val_accuracy: 0.2409 - val_loss: 1.3695 - val_macro_f1: 0.0714 - val_weighted_f1: 0.1573 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.4315 - loss: 0.0961 - macro_f1: 0.1475 - weighted_f1: 0.2406 - val_accuracy: 0.5354 - val_loss: 0.1479 - val_macro_f1: 0.1549 - val_weighted_f1: 0.3221 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4671 - loss: 0.0848 - macro_f1: 0.1742 - weighted_f1: 0.3141 - val_accuracy: 0.3308 - val_loss: 0.7465 - val_macro_f1: 0.0999 - val_weighted_f1: 0.1654 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4798 - loss: 0.0826 - macro_f1: 0.1842 - weighted_f1: 0.3261 - val_accuracy: 0.3476 - val_loss: 0.1721 - val_macro_f1: 0.1147 - val_weighted_f1: 0.2542 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4885 - loss: 0.0787 - macro_f1: 0.2053 - weighted_f1: 0.3657 - val_accuracy: 0.5037 - val_loss: 0.1398 - val_macro_f1: 0.2028 - val_weighted_f1: 0.4025 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5044 - loss: 0.0757 - macro_f1: 0.2268 - weighted_f1: 0.3998 - val_accuracy: 0.3644 - val_loss: 0.1751 - val_macro_f1: 0.1648 - val_weighted_f1: 0.3152 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5124 - loss: 0.0723 - macro_f1: 0.2229 - weighted_f1: 0.4193 - val_accuracy: 0.4916 - val_loss: 0.1322 - val_macro_f1: 0.2053 - val_weighted_f1: 0.4226 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5027 - loss: 0.0761 - macro_f1: 0.2388 - weighted_f1: 0.4153 - val_accuracy: 0.3952 - val_loss: 0.1580 - val_macro_f1: 0.1799 - val_weighted_f1: 0.3425 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5144 - loss: 0.0714 - macro_f1: 0.2414 - weighted_f1: 0.4400 - val_accuracy: 0.5513 - val_loss: 0.1272 - val_macro_f1: 0.2193 - val_weighted_f1: 0.4648 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5377 - loss: 0.0633 - macro_f1: 0.2800 - weighted_f1: 0.4881 - val_accuracy: 0.4609 - val_loss: 0.1342 - val_macro_f1: 0.2170 - val_weighted_f1: 0.4291 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5231 - loss: 0.0628 - macro_f1: 0.2771 - weighted_f1: 0.4904 - val_accuracy: 0.5294 - val_loss: 0.1263 - val_macro_f1: 0.2490 - val_weighted_f1: 0.4929 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5382 - loss: 0.0648 - macro_f1: 0.2835 - weighted_f1: 0.5021 - val_accuracy: 0.5722 - val_loss: 0.1154 - val_macro_f1: 0.2670 - val_weighted_f1: 0.5270 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5528 - loss: 0.0603 - macro_f1: 0.3087 - weighted_f1: 0.5311 - val_accuracy: 0.5298 - val_loss: 0.1249 - val_macro_f1: 0.2504 - val_weighted_f1: 0.4886 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5581 - loss: 0.0550 - macro_f1: 0.3255 - weighted_f1: 0.5520 - val_accuracy: 0.4818 - val_loss: 0.1340 - val_macro_f1: 0.2446 - val_weighted_f1: 0.4639 - learning_rate: 0.0010\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5708 - loss: 0.0551 - macro_f1: 0.3204 - weighted_f1: 0.5563 - val_accuracy: 0.5336 - val_loss: 0.1217 - val_macro_f1: 0.2576 - val_weighted_f1: 0.5071 - learning_rate: 0.0010\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5811 - loss: 0.0513 - macro_f1: 0.3377 - weighted_f1: 0.5829 - val_accuracy: 0.4655 - val_loss: 0.1339 - val_macro_f1: 0.2606 - val_weighted_f1: 0.4034 - learning_rate: 0.0010\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5680 - loss: 0.0511 - macro_f1: 0.3357 - weighted_f1: 0.5700 - val_accuracy: 0.5303 - val_loss: 0.1235 - val_macro_f1: 0.2818 - val_weighted_f1: 0.5466 - learning_rate: 0.0010\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5972 - loss: 0.0457 - macro_f1: 0.3600 - weighted_f1: 0.6096 - val_accuracy: 0.5848 - val_loss: 0.1094 - val_macro_f1: 0.3114 - val_weighted_f1: 0.5914 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6098 - loss: 0.0419 - macro_f1: 0.3917 - weighted_f1: 0.6456 - val_accuracy: 0.5909 - val_loss: 0.1090 - val_macro_f1: 0.3166 - val_weighted_f1: 0.6041 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6220 - loss: 0.0407 - macro_f1: 0.4007 - weighted_f1: 0.6539 - val_accuracy: 0.5885 - val_loss: 0.1093 - val_macro_f1: 0.3232 - val_weighted_f1: 0.6104 - learning_rate: 1.0000e-04\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6235 - loss: 0.0396 - macro_f1: 0.4033 - weighted_f1: 0.6656 - val_accuracy: 0.5871 - val_loss: 0.1111 - val_macro_f1: 0.3217 - val_weighted_f1: 0.6060 - learning_rate: 1.0000e-04\n",
      "Epoch 25/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6175 - loss: 0.0395 - macro_f1: 0.4101 - weighted_f1: 0.6621 - val_accuracy: 0.5839 - val_loss: 0.1121 - val_macro_f1: 0.3230 - val_weighted_f1: 0.6108 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe32006fc40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_sub_model = create_resnet_model(input_shape, num_classes_sub)\n",
    "train_model(resnet_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 118ms/step - accuracy: 0.1426 - loss: 0.1779 - macro_f1: 0.0390 - weighted_f1: 0.0660 - val_accuracy: 0.2861 - val_loss: 0.1798 - val_macro_f1: 0.0691 - val_weighted_f1: 0.0771 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.3543 - loss: 0.0956 - macro_f1: 0.1190 - weighted_f1: 0.2114 - val_accuracy: 0.2074 - val_loss: 0.1901 - val_macro_f1: 0.1105 - val_weighted_f1: 0.1068 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4358 - loss: 0.0729 - macro_f1: 0.1987 - weighted_f1: 0.3284 - val_accuracy: 0.4432 - val_loss: 0.1587 - val_macro_f1: 0.1704 - val_weighted_f1: 0.3453 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.5214 - loss: 0.0601 - macro_f1: 0.2738 - weighted_f1: 0.4634 - val_accuracy: 0.4944 - val_loss: 0.1453 - val_macro_f1: 0.1875 - val_weighted_f1: 0.4038 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5606 - loss: 0.0513 - macro_f1: 0.3161 - weighted_f1: 0.5270 - val_accuracy: 0.4515 - val_loss: 0.1501 - val_macro_f1: 0.1960 - val_weighted_f1: 0.3583 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5755 - loss: 0.0446 - macro_f1: 0.3622 - weighted_f1: 0.5747 - val_accuracy: 0.5368 - val_loss: 0.1358 - val_macro_f1: 0.2132 - val_weighted_f1: 0.4827 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6130 - loss: 0.0397 - macro_f1: 0.3885 - weighted_f1: 0.6239 - val_accuracy: 0.4823 - val_loss: 0.1513 - val_macro_f1: 0.2389 - val_weighted_f1: 0.4776 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6201 - loss: 0.0345 - macro_f1: 0.4278 - weighted_f1: 0.6509 - val_accuracy: 0.5107 - val_loss: 0.1466 - val_macro_f1: 0.2350 - val_weighted_f1: 0.4719 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6449 - loss: 0.0304 - macro_f1: 0.4642 - weighted_f1: 0.6924 - val_accuracy: 0.5121 - val_loss: 0.1528 - val_macro_f1: 0.2120 - val_weighted_f1: 0.4822 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.6579 - loss: 0.0300 - macro_f1: 0.4625 - weighted_f1: 0.7003 - val_accuracy: 0.5270 - val_loss: 0.1548 - val_macro_f1: 0.2396 - val_weighted_f1: 0.5127 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6563 - loss: 0.0271 - macro_f1: 0.4834 - weighted_f1: 0.7259 - val_accuracy: 0.4897 - val_loss: 0.1617 - val_macro_f1: 0.2447 - val_weighted_f1: 0.4998 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7035 - loss: 0.0197 - macro_f1: 0.5352 - weighted_f1: 0.7836 - val_accuracy: 0.5592 - val_loss: 0.1531 - val_macro_f1: 0.2590 - val_weighted_f1: 0.5521 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7266 - loss: 0.0173 - macro_f1: 0.5555 - weighted_f1: 0.8068 - val_accuracy: 0.5596 - val_loss: 0.1549 - val_macro_f1: 0.2634 - val_weighted_f1: 0.5579 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7333 - loss: 0.0159 - macro_f1: 0.5630 - weighted_f1: 0.8202 - val_accuracy: 0.5629 - val_loss: 0.1580 - val_macro_f1: 0.2619 - val_weighted_f1: 0.5541 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7417 - loss: 0.0152 - macro_f1: 0.5777 - weighted_f1: 0.8252 - val_accuracy: 0.5541 - val_loss: 0.1601 - val_macro_f1: 0.2638 - val_weighted_f1: 0.5527 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7405 - loss: 0.0143 - macro_f1: 0.5737 - weighted_f1: 0.8332 - val_accuracy: 0.5713 - val_loss: 0.1597 - val_macro_f1: 0.2661 - val_weighted_f1: 0.5650 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe230434d30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit_sub_model = create_vit_model(input_shape, num_classes_sub)\n",
    "train_model(vit_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, classes):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_threshold = (y_pred >= 0.5).astype(int)\n",
    "    report = classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0, output_dict=True)\n",
    "    print(classification_report(y_test, y_pred_threshold, target_names=classes, zero_division=0))\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.81      0.66      0.73       496\n",
      "         HYP       0.64      0.60      0.62       262\n",
      "          MI       0.82      0.63      0.71       550\n",
      "        NORM       0.82      0.91      0.86       963\n",
      "        STTC       0.79      0.70      0.74       521\n",
      "\n",
      "   micro avg       0.79      0.75      0.77      2792\n",
      "   macro avg       0.77      0.70      0.73      2792\n",
      "weighted avg       0.79      0.75      0.76      2792\n",
      " samples avg       0.78      0.77      0.76      2792\n",
      "\n",
      "ResNet Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.84      0.68      0.75       496\n",
      "         HYP       0.76      0.43      0.55       262\n",
      "          MI       0.78      0.72      0.75       550\n",
      "        NORM       0.84      0.88      0.86       963\n",
      "        STTC       0.76      0.75      0.76       521\n",
      "\n",
      "   micro avg       0.81      0.75      0.78      2792\n",
      "   macro avg       0.80      0.69      0.73      2792\n",
      "weighted avg       0.80      0.75      0.77      2792\n",
      " samples avg       0.79      0.77      0.76      2792\n",
      "\n",
      "ViT Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.77      0.60      0.68       496\n",
      "         HYP       0.57      0.52      0.54       262\n",
      "          MI       0.69      0.61      0.64       550\n",
      "        NORM       0.83      0.80      0.81       963\n",
      "        STTC       0.68      0.76      0.72       521\n",
      "\n",
      "   micro avg       0.74      0.69      0.71      2792\n",
      "   macro avg       0.71      0.66      0.68      2792\n",
      "weighted avg       0.74      0.69      0.71      2792\n",
      " samples avg       0.70      0.71      0.69      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Superdiagnostic Classification Report:\")\n",
    "cnn_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet Superdiagnostic Classification Report:\")\n",
    "resnet_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT Superdiagnostic Classification Report:\")\n",
    "vit_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.82      0.57      0.67       306\n",
      "       CLBBB       0.86      0.89      0.87        54\n",
      "       CRBBB       0.81      0.85      0.83        54\n",
      "       ILBBB       0.08      0.12      0.10         8\n",
      "         IMI       0.75      0.52      0.61       327\n",
      "       IRBBB       0.58      0.71      0.64       112\n",
      "        ISCA       0.63      0.20      0.31        93\n",
      "        ISCI       0.45      0.25      0.32        40\n",
      "        ISC_       0.76      0.41      0.53       128\n",
      "        IVCD       0.11      0.03      0.04        79\n",
      "   LAFB/LPFB       0.82      0.63      0.71       179\n",
      "     LAO/LAE       0.20      0.02      0.04        42\n",
      "         LMI       0.18      0.10      0.13        20\n",
      "         LVH       0.74      0.56      0.64       214\n",
      "        NORM       0.87      0.74      0.80       963\n",
      "        NST_       0.25      0.17      0.20        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.45      0.50      0.48        10\n",
      "         RVH       1.00      0.08      0.15        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.50      0.33      0.40       222\n",
      "         WPW       0.80      0.50      0.62         8\n",
      "        _AVB       0.50      0.23      0.32        82\n",
      "\n",
      "   micro avg       0.75      0.55      0.63      3034\n",
      "   macro avg       0.53      0.37      0.41      3034\n",
      "weighted avg       0.72      0.55      0.61      3034\n",
      " samples avg       0.62      0.59      0.59      3034\n",
      "\n",
      "ResNet Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.80      0.37      0.51       306\n",
      "       CLBBB       0.93      0.93      0.93        54\n",
      "       CRBBB       0.83      0.93      0.88        54\n",
      "       ILBBB       0.18      0.38      0.24         8\n",
      "         IMI       0.78      0.40      0.53       327\n",
      "       IRBBB       0.47      0.70      0.56       112\n",
      "        ISCA       0.37      0.20      0.26        93\n",
      "        ISCI       0.50      0.33      0.39        40\n",
      "        ISC_       0.74      0.44      0.55       128\n",
      "        IVCD       0.00      0.00      0.00        79\n",
      "   LAFB/LPFB       0.75      0.69      0.72       179\n",
      "     LAO/LAE       0.20      0.02      0.04        42\n",
      "         LMI       0.00      0.00      0.00        20\n",
      "         LVH       0.74      0.48      0.58       214\n",
      "        NORM       0.87      0.70      0.77       963\n",
      "        NST_       0.18      0.16      0.17        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.50      0.30      0.38        10\n",
      "         RVH       0.17      0.08      0.11        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.51      0.38      0.44       222\n",
      "         WPW       1.00      0.38      0.55         8\n",
      "        _AVB       0.57      0.33      0.42        82\n",
      "\n",
      "   micro avg       0.72      0.51      0.60      3034\n",
      "   macro avg       0.48      0.36      0.39      3034\n",
      "weighted avg       0.70      0.51      0.58      3034\n",
      " samples avg       0.58      0.55      0.55      3034\n",
      "\n",
      "ViT Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.66      0.42      0.51       306\n",
      "       CLBBB       0.92      0.83      0.87        54\n",
      "       CRBBB       0.90      0.48      0.63        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.68      0.43      0.53       327\n",
      "       IRBBB       0.44      0.41      0.42       112\n",
      "        ISCA       0.15      0.02      0.04        93\n",
      "        ISCI       0.30      0.15      0.20        40\n",
      "        ISC_       0.72      0.36      0.48       128\n",
      "        IVCD       0.10      0.03      0.04        79\n",
      "   LAFB/LPFB       0.68      0.56      0.61       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.20      0.05      0.08        20\n",
      "         LVH       0.51      0.54      0.52       214\n",
      "        NORM       0.83      0.63      0.71       963\n",
      "        NST_       0.06      0.01      0.02        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.11      0.08      0.10        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.45      0.14      0.21       222\n",
      "         WPW       0.67      0.25      0.36         8\n",
      "        _AVB       0.00      0.00      0.00        82\n",
      "\n",
      "   micro avg       0.68      0.43      0.52      3034\n",
      "   macro avg       0.36      0.23      0.28      3034\n",
      "weighted avg       0.61      0.43      0.49      3034\n",
      " samples avg       0.48      0.46      0.45      3034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN Subdiagnostic Classification Report:\")\n",
    "cnn_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet Subdiagnostic Classification Report:\")\n",
    "resnet_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT Subdiagnostic Classification Report:\")\n",
    "vit_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on LwF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "Working on CNN for LwF Now:\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.3383 - loss: 0.1227 - macro_f1: 0.1120 - weighted_f1: 0.2137 - val_accuracy: 0.4776 - val_loss: 0.1444 - val_macro_f1: 0.1634 - val_weighted_f1: 0.3630 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.4732 - loss: 0.0866 - macro_f1: 0.1967 - weighted_f1: 0.3642 - val_accuracy: 0.4786 - val_loss: 0.1414 - val_macro_f1: 0.2297 - val_weighted_f1: 0.4583 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5161 - loss: 0.0780 - macro_f1: 0.2329 - weighted_f1: 0.4590 - val_accuracy: 0.4888 - val_loss: 0.1333 - val_macro_f1: 0.2242 - val_weighted_f1: 0.4177 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5332 - loss: 0.0692 - macro_f1: 0.2651 - weighted_f1: 0.4848 - val_accuracy: 0.5349 - val_loss: 0.1286 - val_macro_f1: 0.2297 - val_weighted_f1: 0.4762 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5519 - loss: 0.0622 - macro_f1: 0.2926 - weighted_f1: 0.5357 - val_accuracy: 0.4217 - val_loss: 0.1466 - val_macro_f1: 0.2132 - val_weighted_f1: 0.3202 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5484 - loss: 0.0597 - macro_f1: 0.3079 - weighted_f1: 0.5365 - val_accuracy: 0.3695 - val_loss: 0.1712 - val_macro_f1: 0.2186 - val_weighted_f1: 0.3737 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5613 - loss: 0.0603 - macro_f1: 0.3039 - weighted_f1: 0.5392 - val_accuracy: 0.5741 - val_loss: 0.1178 - val_macro_f1: 0.2794 - val_weighted_f1: 0.5464 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5884 - loss: 0.0527 - macro_f1: 0.3428 - weighted_f1: 0.5908 - val_accuracy: 0.5829 - val_loss: 0.1107 - val_macro_f1: 0.2887 - val_weighted_f1: 0.5534 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.5925 - loss: 0.0503 - macro_f1: 0.3362 - weighted_f1: 0.5922 - val_accuracy: 0.5610 - val_loss: 0.1208 - val_macro_f1: 0.2965 - val_weighted_f1: 0.5409 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6028 - loss: 0.0477 - macro_f1: 0.3655 - weighted_f1: 0.6237 - val_accuracy: 0.5713 - val_loss: 0.1161 - val_macro_f1: 0.2802 - val_weighted_f1: 0.5505 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6115 - loss: 0.0457 - macro_f1: 0.3777 - weighted_f1: 0.6362 - val_accuracy: 0.5648 - val_loss: 0.1163 - val_macro_f1: 0.2925 - val_weighted_f1: 0.5554 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6013 - loss: 0.0455 - macro_f1: 0.3712 - weighted_f1: 0.6231 - val_accuracy: 0.5983 - val_loss: 0.1108 - val_macro_f1: 0.2984 - val_weighted_f1: 0.5777 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6320 - loss: 0.0413 - macro_f1: 0.3917 - weighted_f1: 0.6532 - val_accuracy: 0.5797 - val_loss: 0.1134 - val_macro_f1: 0.3065 - val_weighted_f1: 0.5874 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6356 - loss: 0.0366 - macro_f1: 0.4231 - weighted_f1: 0.6895 - val_accuracy: 0.6193 - val_loss: 0.1032 - val_macro_f1: 0.3221 - val_weighted_f1: 0.6214 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6567 - loss: 0.0344 - macro_f1: 0.4480 - weighted_f1: 0.7058 - val_accuracy: 0.6244 - val_loss: 0.1041 - val_macro_f1: 0.3303 - val_weighted_f1: 0.6297 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6556 - loss: 0.0328 - macro_f1: 0.4554 - weighted_f1: 0.7132 - val_accuracy: 0.6100 - val_loss: 0.1037 - val_macro_f1: 0.3288 - val_weighted_f1: 0.6332 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6552 - loss: 0.0323 - macro_f1: 0.4572 - weighted_f1: 0.7180 - val_accuracy: 0.6216 - val_loss: 0.1036 - val_macro_f1: 0.3304 - val_weighted_f1: 0.6302 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6674 - loss: 0.0318 - macro_f1: 0.4535 - weighted_f1: 0.7175 - val_accuracy: 0.6198 - val_loss: 0.1048 - val_macro_f1: 0.3293 - val_weighted_f1: 0.6343 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6735 - loss: 0.0303 - macro_f1: 0.4531 - weighted_f1: 0.7186 - val_accuracy: 0.6128 - val_loss: 0.1062 - val_macro_f1: 0.3376 - val_weighted_f1: 0.6333 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6596 - loss: 0.0295 - macro_f1: 0.4654 - weighted_f1: 0.7208 - val_accuracy: 0.6146 - val_loss: 0.1053 - val_macro_f1: 0.3411 - val_weighted_f1: 0.6402 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6652 - loss: 0.0298 - macro_f1: 0.4658 - weighted_f1: 0.7294 - val_accuracy: 0.6235 - val_loss: 0.1049 - val_macro_f1: 0.3388 - val_weighted_f1: 0.6379 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6645 - loss: 0.0294 - macro_f1: 0.4731 - weighted_f1: 0.7338 - val_accuracy: 0.6226 - val_loss: 0.1047 - val_macro_f1: 0.3410 - val_weighted_f1: 0.6407 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6631 - loss: 0.0301 - macro_f1: 0.4643 - weighted_f1: 0.7263 - val_accuracy: 0.6202 - val_loss: 0.1051 - val_macro_f1: 0.3404 - val_weighted_f1: 0.6395 - learning_rate: 1.0000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6715 - loss: 0.0304 - macro_f1: 0.4715 - weighted_f1: 0.7290 - val_accuracy: 0.6156 - val_loss: 0.1051 - val_macro_f1: 0.3416 - val_weighted_f1: 0.6392 - learning_rate: 1.0000e-05\n",
      "Working on ResNet for LwF Now:\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 92ms/step - accuracy: 0.2478 - loss: 0.1605 - macro_f1: 0.0488 - weighted_f1: 0.0941 - val_accuracy: 0.3173 - val_loss: 0.2283 - val_macro_f1: 0.0668 - val_weighted_f1: 0.1658 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.4588 - loss: 0.0962 - macro_f1: 0.1454 - weighted_f1: 0.2722 - val_accuracy: 0.4604 - val_loss: 0.1615 - val_macro_f1: 0.1070 - val_weighted_f1: 0.2882 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4710 - loss: 0.0862 - macro_f1: 0.1716 - weighted_f1: 0.3153 - val_accuracy: 0.3341 - val_loss: 0.1711 - val_macro_f1: 0.1069 - val_weighted_f1: 0.2525 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4753 - loss: 0.0884 - macro_f1: 0.1768 - weighted_f1: 0.3227 - val_accuracy: 0.4814 - val_loss: 0.1415 - val_macro_f1: 0.1878 - val_weighted_f1: 0.4162 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5066 - loss: 0.0734 - macro_f1: 0.2266 - weighted_f1: 0.4221 - val_accuracy: 0.3434 - val_loss: 0.1736 - val_macro_f1: 0.1690 - val_weighted_f1: 0.2603 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4976 - loss: 0.0736 - macro_f1: 0.2381 - weighted_f1: 0.4266 - val_accuracy: 0.4087 - val_loss: 0.1642 - val_macro_f1: 0.1825 - val_weighted_f1: 0.3374 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.4972 - loss: 0.0750 - macro_f1: 0.2302 - weighted_f1: 0.4114 - val_accuracy: 0.4804 - val_loss: 0.1461 - val_macro_f1: 0.1875 - val_weighted_f1: 0.3848 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5280 - loss: 0.0684 - macro_f1: 0.2548 - weighted_f1: 0.4706 - val_accuracy: 0.3481 - val_loss: 0.1616 - val_macro_f1: 0.1824 - val_weighted_f1: 0.2115 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5230 - loss: 0.0637 - macro_f1: 0.2771 - weighted_f1: 0.4859 - val_accuracy: 0.4814 - val_loss: 0.1421 - val_macro_f1: 0.1985 - val_weighted_f1: 0.3659 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5693 - loss: 0.0551 - macro_f1: 0.3163 - weighted_f1: 0.5489 - val_accuracy: 0.5624 - val_loss: 0.1138 - val_macro_f1: 0.2756 - val_weighted_f1: 0.5518 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5861 - loss: 0.0507 - macro_f1: 0.3447 - weighted_f1: 0.5877 - val_accuracy: 0.5638 - val_loss: 0.1140 - val_macro_f1: 0.2874 - val_weighted_f1: 0.5648 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5914 - loss: 0.0480 - macro_f1: 0.3532 - weighted_f1: 0.6021 - val_accuracy: 0.5666 - val_loss: 0.1161 - val_macro_f1: 0.2946 - val_weighted_f1: 0.5638 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5913 - loss: 0.0474 - macro_f1: 0.3611 - weighted_f1: 0.6086 - val_accuracy: 0.5615 - val_loss: 0.1137 - val_macro_f1: 0.2987 - val_weighted_f1: 0.5803 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.5969 - loss: 0.0455 - macro_f1: 0.3687 - weighted_f1: 0.6175 - val_accuracy: 0.5629 - val_loss: 0.1155 - val_macro_f1: 0.2993 - val_weighted_f1: 0.5756 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5999 - loss: 0.0445 - macro_f1: 0.3679 - weighted_f1: 0.6249 - val_accuracy: 0.5797 - val_loss: 0.1150 - val_macro_f1: 0.2999 - val_weighted_f1: 0.5823 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6109 - loss: 0.0420 - macro_f1: 0.3905 - weighted_f1: 0.6477 - val_accuracy: 0.5638 - val_loss: 0.1140 - val_macro_f1: 0.2980 - val_weighted_f1: 0.5855 - learning_rate: 1.0000e-04\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6130 - loss: 0.0421 - macro_f1: 0.4002 - weighted_f1: 0.6460 - val_accuracy: 0.5680 - val_loss: 0.1151 - val_macro_f1: 0.3050 - val_weighted_f1: 0.5737 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6229 - loss: 0.0389 - macro_f1: 0.4123 - weighted_f1: 0.6623 - val_accuracy: 0.5718 - val_loss: 0.1191 - val_macro_f1: 0.3033 - val_weighted_f1: 0.5992 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6304 - loss: 0.0359 - macro_f1: 0.4222 - weighted_f1: 0.6834 - val_accuracy: 0.5857 - val_loss: 0.1138 - val_macro_f1: 0.3111 - val_weighted_f1: 0.5981 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.6407 - loss: 0.0349 - macro_f1: 0.4353 - weighted_f1: 0.6890 - val_accuracy: 0.5834 - val_loss: 0.1145 - val_macro_f1: 0.3158 - val_weighted_f1: 0.6082 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6393 - loss: 0.0339 - macro_f1: 0.4411 - weighted_f1: 0.6988 - val_accuracy: 0.5867 - val_loss: 0.1155 - val_macro_f1: 0.3152 - val_weighted_f1: 0.6095 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6369 - loss: 0.0343 - macro_f1: 0.4368 - weighted_f1: 0.6963 - val_accuracy: 0.5839 - val_loss: 0.1188 - val_macro_f1: 0.3130 - val_weighted_f1: 0.6025 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.6310 - loss: 0.0335 - macro_f1: 0.4416 - weighted_f1: 0.6946 - val_accuracy: 0.5848 - val_loss: 0.1188 - val_macro_f1: 0.3143 - val_weighted_f1: 0.6077 - learning_rate: 1.0000e-05\n",
      "Working on ViT for LwF Now:\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step\n",
      "Epoch 1/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 111ms/step - accuracy: 0.1626 - loss: 0.1429 - macro_f1: 0.0463 - weighted_f1: 0.0758 - val_accuracy: 0.3010 - val_loss: 0.1963 - val_macro_f1: 0.0504 - val_weighted_f1: 0.0415 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.3429 - loss: 0.1014 - macro_f1: 0.0929 - weighted_f1: 0.1772 - val_accuracy: 0.3914 - val_loss: 0.1712 - val_macro_f1: 0.0890 - val_weighted_f1: 0.2108 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4395 - loss: 0.0713 - macro_f1: 0.1926 - weighted_f1: 0.3336 - val_accuracy: 0.3984 - val_loss: 0.1671 - val_macro_f1: 0.1843 - val_weighted_f1: 0.3864 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5190 - loss: 0.0575 - macro_f1: 0.2896 - weighted_f1: 0.4684 - val_accuracy: 0.4818 - val_loss: 0.1477 - val_macro_f1: 0.1780 - val_weighted_f1: 0.3439 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.5677 - loss: 0.0486 - macro_f1: 0.3409 - weighted_f1: 0.5383 - val_accuracy: 0.5270 - val_loss: 0.1403 - val_macro_f1: 0.2271 - val_weighted_f1: 0.4847 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.6038 - loss: 0.0404 - macro_f1: 0.3940 - weighted_f1: 0.6172 - val_accuracy: 0.5275 - val_loss: 0.1449 - val_macro_f1: 0.2225 - val_weighted_f1: 0.4963 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6193 - loss: 0.0365 - macro_f1: 0.4203 - weighted_f1: 0.6443 - val_accuracy: 0.5280 - val_loss: 0.1542 - val_macro_f1: 0.2456 - val_weighted_f1: 0.5179 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6537 - loss: 0.0318 - macro_f1: 0.4482 - weighted_f1: 0.6842 - val_accuracy: 0.5326 - val_loss: 0.1506 - val_macro_f1: 0.2287 - val_weighted_f1: 0.4900 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6585 - loss: 0.0290 - macro_f1: 0.4736 - weighted_f1: 0.7126 - val_accuracy: 0.5275 - val_loss: 0.1591 - val_macro_f1: 0.2503 - val_weighted_f1: 0.5277 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6741 - loss: 0.0257 - macro_f1: 0.5037 - weighted_f1: 0.7317 - val_accuracy: 0.5457 - val_loss: 0.1620 - val_macro_f1: 0.2475 - val_weighted_f1: 0.5340 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7098 - loss: 0.0196 - macro_f1: 0.5425 - weighted_f1: 0.7870 - val_accuracy: 0.5555 - val_loss: 0.1559 - val_macro_f1: 0.2597 - val_weighted_f1: 0.5563 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7335 - loss: 0.0166 - macro_f1: 0.5694 - weighted_f1: 0.8148 - val_accuracy: 0.5638 - val_loss: 0.1563 - val_macro_f1: 0.2572 - val_weighted_f1: 0.5579 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7385 - loss: 0.0151 - macro_f1: 0.5825 - weighted_f1: 0.8294 - val_accuracy: 0.5596 - val_loss: 0.1592 - val_macro_f1: 0.2618 - val_weighted_f1: 0.5629 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7502 - loss: 0.0144 - macro_f1: 0.5885 - weighted_f1: 0.8382 - val_accuracy: 0.5648 - val_loss: 0.1606 - val_macro_f1: 0.2533 - val_weighted_f1: 0.5524 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7477 - loss: 0.0138 - macro_f1: 0.5842 - weighted_f1: 0.8430 - val_accuracy: 0.5606 - val_loss: 0.1635 - val_macro_f1: 0.2578 - val_weighted_f1: 0.5564 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fda23178280>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_soft_targets_super = cnn_super_model.predict(X_train)\n",
    "\n",
    "def lwf_loss(y_true, y_pred, old_predictions, T=2):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    dist_loss = tf.keras.losses.KLDivergence()(tf.nn.softmax(old_predictions / T),\n",
    "                                               tf.nn.softmax(y_pred / T))\n",
    "    total_loss = task_loss + dist_loss\n",
    "    return total_loss\n",
    "\n",
    "print(\"Working on CNN for LwF Now:\")\n",
    "cnn_model_lwf = create_cnn_model(input_shape, num_classes_sub)\n",
    "cnn_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=cnn_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(cnn_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n",
    "\n",
    "print(\"Working on ResNet for LwF Now:\")\n",
    "resnet_soft_targets_super = resnet_super_model.predict(X_train)\n",
    "resnet_model_lwf = create_resnet_model(input_shape, num_classes_sub)\n",
    "resnet_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=resnet_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(resnet_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n",
    "\n",
    "print(\"Working on ViT for LwF Now:\")\n",
    "vit_soft_targets_super = vit_super_model.predict(X_train)\n",
    "vit_model_lwf = create_vit_model(input_shape, num_classes_sub)\n",
    "vit_model_lwf.compile(\n",
    "    optimizer='adam',\n",
    "    loss=lambda y_true, y_pred: lwf_loss(y_true, y_pred, old_predictions=vit_soft_targets_super),\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "train_model(vit_model_lwf, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on EwC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC:\n",
    "    def __init__(self, model, X, y, batch_size=32, exclude_params=[]):\n",
    "        self.model = model\n",
    "        self.params = {}\n",
    "        for p in model.trainable_variables:\n",
    "            if id(p) not in exclude_params:\n",
    "                self.params[id(p)] = p.numpy()\n",
    "        self.fisher = self.compute_fisher(X, y, batch_size, exclude_params)\n",
    "\n",
    "    def compute_fisher(self, X, y, batch_size, exclude_params):\n",
    "        fisher = {}\n",
    "        num_samples = X.shape[0]\n",
    "        num_batches = int(np.ceil(num_samples / batch_size))\n",
    "\n",
    "        for batch_idx in range(num_batches):\n",
    "            X_batch = X[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            y_batch = y[batch_idx*batch_size:(batch_idx+1)*batch_size]\n",
    "            with tf.GradientTape() as tape:\n",
    "                preds = self.model(X_batch)\n",
    "                loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            for p, g in zip(self.model.trainable_variables, grads):\n",
    "                if g is not None and id(p) not in exclude_params:\n",
    "                    param_id = id(p)\n",
    "                    if param_id not in fisher:\n",
    "                        fisher[param_id] = np.square(g.numpy())\n",
    "                    else:\n",
    "                        fisher[param_id] += np.square(g.numpy())\n",
    "        for k in fisher.keys():\n",
    "            fisher[k] /= num_batches\n",
    "        return fisher\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0\n",
    "        for p in model.trainable_variables:\n",
    "            param_id = id(p)\n",
    "            if param_id in self.fisher:\n",
    "                fisher = tf.convert_to_tensor(self.fisher[param_id])\n",
    "                loss += tf.reduce_sum(fisher * tf.square(p - self.params[param_id]))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic(base_model, num_classes_sub):\n",
    "    inputs = base_model.input\n",
    "    x = inputs\n",
    "    for layer in base_model.layers[1:-1]:\n",
    "        x = layer(x)\n",
    "    outputs = layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    new_model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.5276 - loss: 0.1146 - macro_f1: 0.2026 - weighted_f1: 0.4466 - val_accuracy: 0.5718 - val_loss: 0.1227 - val_macro_f1: 0.2635 - val_weighted_f1: 0.5418 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6050 - loss: 0.0623 - macro_f1: 0.3203 - weighted_f1: 0.5937 - val_accuracy: 0.5801 - val_loss: 0.1207 - val_macro_f1: 0.2876 - val_weighted_f1: 0.5552 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6120 - loss: 0.0575 - macro_f1: 0.3417 - weighted_f1: 0.6026 - val_accuracy: 0.6109 - val_loss: 0.1070 - val_macro_f1: 0.3139 - val_weighted_f1: 0.6064 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6372 - loss: 0.0514 - macro_f1: 0.3578 - weighted_f1: 0.6384 - val_accuracy: 0.6021 - val_loss: 0.1078 - val_macro_f1: 0.2954 - val_weighted_f1: 0.5887 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6395 - loss: 0.0460 - macro_f1: 0.3847 - weighted_f1: 0.6496 - val_accuracy: 0.6067 - val_loss: 0.1100 - val_macro_f1: 0.3182 - val_weighted_f1: 0.6181 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.6471 - loss: 0.0430 - macro_f1: 0.3910 - weighted_f1: 0.6635 - val_accuracy: 0.6104 - val_loss: 0.1060 - val_macro_f1: 0.3205 - val_weighted_f1: 0.6233 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6497 - loss: 0.0403 - macro_f1: 0.4111 - weighted_f1: 0.6800 - val_accuracy: 0.5904 - val_loss: 0.1133 - val_macro_f1: 0.3169 - val_weighted_f1: 0.6044 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6547 - loss: 0.0397 - macro_f1: 0.4130 - weighted_f1: 0.6885 - val_accuracy: 0.5941 - val_loss: 0.1116 - val_macro_f1: 0.3108 - val_weighted_f1: 0.5941 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6616 - loss: 0.0353 - macro_f1: 0.4339 - weighted_f1: 0.7058 - val_accuracy: 0.5755 - val_loss: 0.1144 - val_macro_f1: 0.3279 - val_weighted_f1: 0.6263 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6782 - loss: 0.0315 - macro_f1: 0.4609 - weighted_f1: 0.7308 - val_accuracy: 0.5979 - val_loss: 0.1136 - val_macro_f1: 0.3171 - val_weighted_f1: 0.6146 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6770 - loss: 0.0298 - macro_f1: 0.4761 - weighted_f1: 0.7448 - val_accuracy: 0.5531 - val_loss: 0.1196 - val_macro_f1: 0.3167 - val_weighted_f1: 0.5944 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.6974 - loss: 0.0251 - macro_f1: 0.5051 - weighted_f1: 0.7753 - val_accuracy: 0.6351 - val_loss: 0.1063 - val_macro_f1: 0.3391 - val_weighted_f1: 0.6476 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7076 - loss: 0.0225 - macro_f1: 0.5171 - weighted_f1: 0.7920 - val_accuracy: 0.6314 - val_loss: 0.1076 - val_macro_f1: 0.3526 - val_weighted_f1: 0.6508 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7150 - loss: 0.0219 - macro_f1: 0.5247 - weighted_f1: 0.7938 - val_accuracy: 0.6351 - val_loss: 0.1075 - val_macro_f1: 0.3465 - val_weighted_f1: 0.6511 - learning_rate: 1.0000e-04\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7161 - loss: 0.0212 - macro_f1: 0.5376 - weighted_f1: 0.7994 - val_accuracy: 0.6323 - val_loss: 0.1086 - val_macro_f1: 0.3468 - val_weighted_f1: 0.6530 - learning_rate: 1.0000e-04\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7244 - loss: 0.0202 - macro_f1: 0.5362 - weighted_f1: 0.8037 - val_accuracy: 0.6337 - val_loss: 0.1101 - val_macro_f1: 0.3431 - val_weighted_f1: 0.6501 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe210a03040>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_ewc = 1000\n",
    "cnn_sub_model = modify_model_for_subdiagnostic(cnn_super_model, num_classes_sub)\n",
    "exclude_params_cnn = [id(w) for w in cnn_sub_model.layers[-1].trainable_weights]\n",
    "ewc_cnn = EWC(cnn_super_model, X_train, y_train_super, exclude_params=exclude_params_cnn)\n",
    "\n",
    "def ewc_loss_cnn(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_cnn.penalty(cnn_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "cnn_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_cnn,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(cnn_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic_resnet(base_model, num_classes_sub):\n",
    "    x = base_model.layers[-2].output\n",
    "    outputs = layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    new_model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 93ms/step - accuracy: 0.4240 - loss: 0.1152 - macro_f1: 0.1485 - weighted_f1: 0.3050 - val_accuracy: 0.4744 - val_loss: 0.1427 - val_macro_f1: 0.2107 - val_weighted_f1: 0.4426 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5310 - loss: 0.0766 - macro_f1: 0.2384 - weighted_f1: 0.4613 - val_accuracy: 0.4264 - val_loss: 0.1474 - val_macro_f1: 0.1707 - val_weighted_f1: 0.3584 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5423 - loss: 0.0733 - macro_f1: 0.2413 - weighted_f1: 0.4751 - val_accuracy: 0.5550 - val_loss: 0.1356 - val_macro_f1: 0.2428 - val_weighted_f1: 0.5199 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5764 - loss: 0.0689 - macro_f1: 0.2624 - weighted_f1: 0.5109 - val_accuracy: 0.5573 - val_loss: 0.1227 - val_macro_f1: 0.2508 - val_weighted_f1: 0.5171 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5914 - loss: 0.0647 - macro_f1: 0.2933 - weighted_f1: 0.5541 - val_accuracy: 0.2386 - val_loss: 0.2229 - val_macro_f1: 0.1591 - val_weighted_f1: 0.2289 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.5648 - loss: 0.0652 - macro_f1: 0.2814 - weighted_f1: 0.5209 - val_accuracy: 0.5238 - val_loss: 0.1339 - val_macro_f1: 0.1963 - val_weighted_f1: 0.3964 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5809 - loss: 0.0607 - macro_f1: 0.3086 - weighted_f1: 0.5548 - val_accuracy: 0.5377 - val_loss: 0.1269 - val_macro_f1: 0.2899 - val_weighted_f1: 0.5491 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6041 - loss: 0.0555 - macro_f1: 0.3272 - weighted_f1: 0.5942 - val_accuracy: 0.5261 - val_loss: 0.1267 - val_macro_f1: 0.2461 - val_weighted_f1: 0.4459 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.5985 - loss: 0.0537 - macro_f1: 0.3326 - weighted_f1: 0.5967 - val_accuracy: 0.5387 - val_loss: 0.1201 - val_macro_f1: 0.2889 - val_weighted_f1: 0.5315 - learning_rate: 0.0010\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6091 - loss: 0.0495 - macro_f1: 0.3544 - weighted_f1: 0.6222 - val_accuracy: 0.5466 - val_loss: 0.1150 - val_macro_f1: 0.2951 - val_weighted_f1: 0.5712 - learning_rate: 0.0010\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6074 - loss: 0.0475 - macro_f1: 0.3655 - weighted_f1: 0.6315 - val_accuracy: 0.5774 - val_loss: 0.1113 - val_macro_f1: 0.3136 - val_weighted_f1: 0.5919 - learning_rate: 0.0010\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6282 - loss: 0.0451 - macro_f1: 0.3785 - weighted_f1: 0.6461 - val_accuracy: 0.5704 - val_loss: 0.1128 - val_macro_f1: 0.3175 - val_weighted_f1: 0.5897 - learning_rate: 0.0010\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6259 - loss: 0.0432 - macro_f1: 0.3762 - weighted_f1: 0.6510 - val_accuracy: 0.5135 - val_loss: 0.1279 - val_macro_f1: 0.2829 - val_weighted_f1: 0.5440 - learning_rate: 0.0010\n",
      "Epoch 14/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6100 - loss: 0.0450 - macro_f1: 0.3789 - weighted_f1: 0.6358 - val_accuracy: 0.5610 - val_loss: 0.1257 - val_macro_f1: 0.2882 - val_weighted_f1: 0.5480 - learning_rate: 0.0010\n",
      "Epoch 15/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6379 - loss: 0.0409 - macro_f1: 0.4047 - weighted_f1: 0.6751 - val_accuracy: 0.5601 - val_loss: 0.1217 - val_macro_f1: 0.3067 - val_weighted_f1: 0.5791 - learning_rate: 0.0010\n",
      "Epoch 16/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6367 - loss: 0.0407 - macro_f1: 0.4148 - weighted_f1: 0.6679 - val_accuracy: 0.6062 - val_loss: 0.1188 - val_macro_f1: 0.2957 - val_weighted_f1: 0.5816 - learning_rate: 0.0010\n",
      "Epoch 17/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6515 - loss: 0.0387 - macro_f1: 0.4073 - weighted_f1: 0.6833 - val_accuracy: 0.6184 - val_loss: 0.1051 - val_macro_f1: 0.3362 - val_weighted_f1: 0.6361 - learning_rate: 1.0000e-04\n",
      "Epoch 18/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6645 - loss: 0.0319 - macro_f1: 0.4448 - weighted_f1: 0.7231 - val_accuracy: 0.6253 - val_loss: 0.1075 - val_macro_f1: 0.3442 - val_weighted_f1: 0.6469 - learning_rate: 1.0000e-04\n",
      "Epoch 19/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6848 - loss: 0.0303 - macro_f1: 0.4639 - weighted_f1: 0.7376 - val_accuracy: 0.6226 - val_loss: 0.1089 - val_macro_f1: 0.3408 - val_weighted_f1: 0.6494 - learning_rate: 1.0000e-04\n",
      "Epoch 20/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6894 - loss: 0.0291 - macro_f1: 0.4733 - weighted_f1: 0.7486 - val_accuracy: 0.6277 - val_loss: 0.1087 - val_macro_f1: 0.3442 - val_weighted_f1: 0.6520 - learning_rate: 1.0000e-04\n",
      "Epoch 21/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6798 - loss: 0.0280 - macro_f1: 0.4770 - weighted_f1: 0.7469 - val_accuracy: 0.6151 - val_loss: 0.1109 - val_macro_f1: 0.3439 - val_weighted_f1: 0.6498 - learning_rate: 1.0000e-04\n",
      "Epoch 22/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6918 - loss: 0.0267 - macro_f1: 0.4857 - weighted_f1: 0.7588 - val_accuracy: 0.6118 - val_loss: 0.1130 - val_macro_f1: 0.3498 - val_weighted_f1: 0.6535 - learning_rate: 1.0000e-04\n",
      "Epoch 23/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6918 - loss: 0.0252 - macro_f1: 0.5057 - weighted_f1: 0.7662 - val_accuracy: 0.6142 - val_loss: 0.1132 - val_macro_f1: 0.3451 - val_weighted_f1: 0.6473 - learning_rate: 1.0000e-05\n",
      "Epoch 24/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6987 - loss: 0.0246 - macro_f1: 0.5106 - weighted_f1: 0.7732 - val_accuracy: 0.6142 - val_loss: 0.1134 - val_macro_f1: 0.3452 - val_weighted_f1: 0.6498 - learning_rate: 1.0000e-05\n",
      "Epoch 25/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.6946 - loss: 0.0246 - macro_f1: 0.5053 - weighted_f1: 0.7740 - val_accuracy: 0.6118 - val_loss: 0.1137 - val_macro_f1: 0.3470 - val_weighted_f1: 0.6504 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd8b6161e50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "resnet_sub_model = modify_model_for_subdiagnostic_resnet(resnet_super_model, num_classes_sub)\n",
    "exclude_params_resnet = [w.name for w in resnet_sub_model.layers[-1].trainable_weights]\n",
    "def ewc_loss_resnet(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_resnet.penalty(resnet_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "resnet_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_resnet,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(resnet_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_model_for_subdiagnostic_vit(base_model, num_classes_sub):\n",
    "    # Get the output of the layer before the last\n",
    "    x = base_model.layers[-2].output  # Exclude the last layer\n",
    "    # Add new output layer for subdiagnostic task\n",
    "    outputs = layers.Dense(num_classes_sub, activation='sigmoid', name='output_sub')(x)\n",
    "    # Create new model\n",
    "    new_model = tf.keras.Model(inputs=base_model.input, outputs=outputs)\n",
    "    return new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m264/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4485 - loss: 0.1181 - macro_f1: 0.1404 - weighted_f1: 0.3141"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 114ms/step - accuracy: 0.4491 - loss: 0.1178 - macro_f1: 0.1409 - weighted_f1: 0.3149 - val_accuracy: 0.5191 - val_loss: 0.1394 - val_macro_f1: 0.2031 - val_weighted_f1: 0.4773 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.5377 - loss: 0.0708 - macro_f1: 0.2530 - weighted_f1: 0.4652 - val_accuracy: 0.5214 - val_loss: 0.1376 - val_macro_f1: 0.2281 - val_weighted_f1: 0.4723 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6029 - loss: 0.0539 - macro_f1: 0.3121 - weighted_f1: 0.5650 - val_accuracy: 0.5769 - val_loss: 0.1262 - val_macro_f1: 0.2494 - val_weighted_f1: 0.5596 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.6274 - loss: 0.0422 - macro_f1: 0.3718 - weighted_f1: 0.6300 - val_accuracy: 0.5788 - val_loss: 0.1288 - val_macro_f1: 0.2347 - val_weighted_f1: 0.5244 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6539 - loss: 0.0360 - macro_f1: 0.4207 - weighted_f1: 0.6707 - val_accuracy: 0.5158 - val_loss: 0.1438 - val_macro_f1: 0.2490 - val_weighted_f1: 0.5202 - learning_rate: 0.0010\n",
      "Epoch 6/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6709 - loss: 0.0304 - macro_f1: 0.4559 - weighted_f1: 0.7076 - val_accuracy: 0.5238 - val_loss: 0.1464 - val_macro_f1: 0.2399 - val_weighted_f1: 0.5013 - learning_rate: 0.0010\n",
      "Epoch 7/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6866 - loss: 0.0269 - macro_f1: 0.4866 - weighted_f1: 0.7321 - val_accuracy: 0.5410 - val_loss: 0.1483 - val_macro_f1: 0.2682 - val_weighted_f1: 0.5657 - learning_rate: 0.0010\n",
      "Epoch 8/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.6980 - loss: 0.0238 - macro_f1: 0.5085 - weighted_f1: 0.7623 - val_accuracy: 0.5545 - val_loss: 0.1470 - val_macro_f1: 0.2654 - val_weighted_f1: 0.5608 - learning_rate: 0.0010\n",
      "Epoch 9/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.7324 - loss: 0.0180 - macro_f1: 0.5509 - weighted_f1: 0.8102 - val_accuracy: 0.5666 - val_loss: 0.1522 - val_macro_f1: 0.2796 - val_weighted_f1: 0.5735 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7520 - loss: 0.0155 - macro_f1: 0.5710 - weighted_f1: 0.8324 - val_accuracy: 0.5755 - val_loss: 0.1551 - val_macro_f1: 0.2795 - val_weighted_f1: 0.5849 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7558 - loss: 0.0143 - macro_f1: 0.5757 - weighted_f1: 0.8432 - val_accuracy: 0.5718 - val_loss: 0.1570 - val_macro_f1: 0.2747 - val_weighted_f1: 0.5806 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - accuracy: 0.7565 - loss: 0.0136 - macro_f1: 0.5944 - weighted_f1: 0.8514 - val_accuracy: 0.5843 - val_loss: 0.1578 - val_macro_f1: 0.2837 - val_weighted_f1: 0.5933 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.7680 - loss: 0.0124 - macro_f1: 0.5931 - weighted_f1: 0.8605 - val_accuracy: 0.5760 - val_loss: 0.1610 - val_macro_f1: 0.2810 - val_weighted_f1: 0.5883 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd8747d93d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modify ViT model for subdiagnostic task\n",
    "num_classes_sub = y_train_sub.shape[1]\n",
    "vit_sub_model = modify_model_for_subdiagnostic_vit(vit_super_model, num_classes_sub)\n",
    "\n",
    "# Exclude the new output layer's parameters from EWC or SI calculations\n",
    "exclude_params_vit = [w.name for w in vit_sub_model.layers[-1].trainable_weights]\n",
    "\n",
    "def ewc_loss_vit(y_true, y_pred):\n",
    "    task_loss = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "    ewc_penalty = ewc_vit.penalty(vit_sub_model)\n",
    "    total_loss = task_loss + (lambda_ewc / 2) * ewc_penalty\n",
    "    return total_loss\n",
    "\n",
    "vit_sub_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=ewc_loss_vit,\n",
    "    metrics=[macro_f1, weighted_f1]\n",
    ")\n",
    "\n",
    "train_model(vit_sub_model, X_train, y_train_sub, X_val, y_val_sub, class_weight_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining and Training on SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SI:\n",
    "    def __init__(self, prev_model, damping_factor=0.1, exclude_params=[]):\n",
    "        self.prev_params = {}\n",
    "        self.omega = {}\n",
    "        self.damping_factor = damping_factor\n",
    "        self.exclude_params = exclude_params\n",
    "\n",
    "        self.delta_params = {}\n",
    "\n",
    "        # Store parameters from the previous model (superdiagnostic task)\n",
    "        for var in prev_model.trainable_variables:\n",
    "            if var.name not in self.exclude_params:\n",
    "                self.prev_params[var.name] = var.numpy().copy()\n",
    "                self.omega[var.name] = np.zeros_like(var.numpy())\n",
    "                self.delta_params[var.name] = np.zeros_like(var.numpy())\n",
    "\n",
    "    def accumulate_importance(self, model, grads):\n",
    "        for var, grad in zip(model.trainable_variables, grads):\n",
    "            if grad is not None and var.name in self.prev_params:\n",
    "                if var.shape == self.prev_params[var.name].shape:\n",
    "                    delta_theta = var.numpy() - self.prev_params[var.name]\n",
    "                    self.delta_params[var.name] += delta_theta\n",
    "                    # Update omega with absolute value to prevent negative importance\n",
    "                    self.omega[var.name] += np.abs(grad.numpy() * delta_theta)\n",
    "                else:\n",
    "                    # Skip variables with mismatched shapes\n",
    "                    pass\n",
    "\n",
    "    def update_omega(self):\n",
    "        # Normalize omega after training\n",
    "        for var_name in self.omega.keys():\n",
    "            delta_param = self.delta_params[var_name]\n",
    "            denom = np.square(delta_param) + self.damping_factor\n",
    "            self.omega[var_name] = np.divide(self.omega[var_name], denom)\n",
    "            # Ensure omega is non-negative\n",
    "            self.omega[var_name] = np.abs(self.omega[var_name])\n",
    "            # Reset delta_params for the next task\n",
    "            self.delta_params[var_name] = np.zeros_like(delta_param)\n",
    "\n",
    "    def penalty(self, model):\n",
    "        loss = 0\n",
    "        for var in model.trainable_variables:\n",
    "            if var.name in self.prev_params:\n",
    "                prev_param = self.prev_params[var.name]\n",
    "                if var.shape == prev_param.shape:\n",
    "                    omega = tf.convert_to_tensor(self.omega[var.name], dtype=var.dtype)\n",
    "                    prev_param = tf.convert_to_tensor(prev_param, dtype=var.dtype)\n",
    "                    # Ensure omega is non-negative\n",
    "                    loss += tf.reduce_sum(omega * tf.square(var - prev_param))\n",
    "                else:\n",
    "                    # Skip variables with mismatched shapes\n",
    "                    pass\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes_sub = y_train_sub.shape[1]\n",
    "cnn_sub_model = modify_model_for_subdiagnostic(cnn_super_model, num_classes_sub)\n",
    "exclude_params_cnn = [w.name for w in cnn_sub_model.layers[-1].trainable_weights]\n",
    "si_cnn = SI(cnn_super_model, exclude_params=exclude_params_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CNN Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 133/266 [00:23<00:22,  6.02it/s, loss=0.118, macro_f1=0.26] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 45.33s, Loss: 0.1034, Macro F1: 0.3007, Val Loss: 0.0991, Val Macro F1: 0.3018\n",
      "\n",
      "CNN Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 42.52s, Loss: 0.0801, Macro F1: 0.3638, Val Loss: 0.0985, Val Macro F1: 0.3144\n",
      "\n",
      "CNN Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 42.80s, Loss: 0.0727, Macro F1: 0.3947, Val Loss: 0.1003, Val Macro F1: 0.3161\n",
      "\n",
      "CNN Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 43.61s, Loss: 0.0659, Macro F1: 0.4205, Val Loss: 0.1042, Val Macro F1: 0.3126\n",
      "\n",
      "CNN Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 43.50s, Loss: 0.0591, Macro F1: 0.4541, Val Loss: 0.1095, Val Macro F1: 0.3195\n",
      "\n",
      "CNN Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 43.88s, Loss: 0.0518, Macro F1: 0.4919, Val Loss: 0.1178, Val Macro F1: 0.3075\n",
      "\n",
      "CNN Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 43.54s, Loss: 0.0445, Macro F1: 0.5265, Val Loss: 0.1277, Val Macro F1: 0.3093\n",
      "\n",
      "CNN Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 42.67s, Loss: 0.0379, Macro F1: 0.5556, Val Loss: 0.1361, Val Macro F1: 0.3146\n",
      "\n",
      "CNN Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 43.02s, Loss: 0.0322, Macro F1: 0.5781, Val Loss: 0.1476, Val Macro F1: 0.3201\n",
      "\n",
      "CNN Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 43.81s, Loss: 0.0288, Macro F1: 0.5936, Val Loss: 0.1589, Val Macro F1: 0.3214\n",
      "\n",
      "CNN Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 44.23s, Loss: 0.0257, Macro F1: 0.6034, Val Loss: 0.1705, Val Macro F1: 0.3150\n",
      "\n",
      "CNN Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 43.91s, Loss: 0.0223, Macro F1: 0.6178, Val Loss: 0.1821, Val Macro F1: 0.3142\n",
      "\n",
      "CNN Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 42.51s, Loss: 0.0194, Macro F1: 0.6292, Val Loss: 0.1887, Val Macro F1: 0.3105\n",
      "\n",
      "CNN Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 42.09s, Loss: 0.0171, Macro F1: 0.6389, Val Loss: 0.2029, Val Macro F1: 0.3135\n",
      "\n",
      "CNN Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 43.45s, Loss: 0.0147, Macro F1: 0.6496, Val Loss: 0.2021, Val Macro F1: 0.3191\n",
      "\n",
      "CNN Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 44.50s, Loss: 0.0132, Macro F1: 0.6521, Val Loss: 0.2159, Val Macro F1: 0.3147\n",
      "\n",
      "CNN Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 43.81s, Loss: 0.0124, Macro F1: 0.6572, Val Loss: 0.2341, Val Macro F1: 0.3144\n",
      "\n",
      "CNN Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 44.12s, Loss: 0.0113, Macro F1: 0.6580, Val Loss: 0.2340, Val Macro F1: 0.3235\n",
      "\n",
      "CNN Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 44.15s, Loss: 0.0093, Macro F1: 0.6670, Val Loss: 0.2421, Val Macro F1: 0.3082\n",
      "\n",
      "CNN Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 42.79s, Loss: 0.0087, Macro F1: 0.6674, Val Loss: 0.2393, Val Macro F1: 0.3167\n",
      "\n",
      "CNN Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 42.50s, Loss: 0.0083, Macro F1: 0.6688, Val Loss: 0.2536, Val Macro F1: 0.3102\n",
      "\n",
      "CNN Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 44.38s, Loss: 0.0081, Macro F1: 0.6702, Val Loss: 0.2625, Val Macro F1: 0.3043\n",
      "\n",
      "CNN Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 44.74s, Loss: 0.0081, Macro F1: 0.6710, Val Loss: 0.2563, Val Macro F1: 0.3087\n",
      "\n",
      "CNN Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 44.27s, Loss: 0.0079, Macro F1: 0.6726, Val Loss: 0.2486, Val Macro F1: 0.3270\n",
      "\n",
      "CNN Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 43.60s, Loss: 0.0066, Macro F1: 0.6764, Val Loss: 0.2587, Val Macro F1: 0.3030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1.0  # Adjust as needed\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nCNN Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = cnn_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_cnn.penalty(cnn_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        grads = tape.gradient(total_loss, cnn_sub_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, cnn_sub_model.trainable_variables))\n",
    "        si_cnn.accumulate_importance(cnn_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = cnn_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "# After training, update omega\n",
    "si_cnn.update_omega()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_sub_model = modify_model_for_subdiagnostic_resnet(resnet_super_model, num_classes_sub)\n",
    "exclude_params_resnet = [w.name for w in resnet_sub_model.layers[-1].trainable_weights]\n",
    "si_resnet = SI(resnet_sub_model, exclude_params=exclude_params_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ResNet Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 279.33s, Loss: 7193.5806, Macro F1: 0.2916, Val Loss: 0.1096, Val Macro F1: 0.2913\n",
      "\n",
      "ResNet Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 274.20s, Loss: 13.3913, Macro F1: 0.3589, Val Loss: 0.1095, Val Macro F1: 0.3044\n",
      "\n",
      "ResNet Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 273.91s, Loss: 0.0810, Macro F1: 0.3878, Val Loss: 0.1154, Val Macro F1: 0.2950\n",
      "\n",
      "ResNet Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 283.23s, Loss: 0.0731, Macro F1: 0.4198, Val Loss: 0.1261, Val Macro F1: 0.2878\n",
      "\n",
      "ResNet Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 277.55s, Loss: 0.0688, Macro F1: 0.4509, Val Loss: 0.1499, Val Macro F1: 0.2708\n",
      "\n",
      "ResNet Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 275.62s, Loss: 0.0635, Macro F1: 0.4745, Val Loss: 0.1609, Val Macro F1: 0.2913\n",
      "\n",
      "ResNet Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 278.39s, Loss: 0.0581, Macro F1: 0.4884, Val Loss: 0.1640, Val Macro F1: 0.3019\n",
      "\n",
      "ResNet Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 281.06s, Loss: 0.0533, Macro F1: 0.5099, Val Loss: 0.1720, Val Macro F1: 0.2923\n",
      "\n",
      "ResNet Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 278.81s, Loss: 0.0477, Macro F1: 0.5325, Val Loss: 0.1768, Val Macro F1: 0.2930\n",
      "\n",
      "ResNet Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 278.85s, Loss: 0.0444, Macro F1: 0.5519, Val Loss: 0.1874, Val Macro F1: 0.2964\n",
      "\n",
      "ResNet Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 278.03s, Loss: 0.0367, Macro F1: 0.5704, Val Loss: 0.2016, Val Macro F1: 0.3108\n",
      "\n",
      "ResNet Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 279.32s, Loss: 0.0345, Macro F1: 0.5914, Val Loss: 0.2183, Val Macro F1: 0.3104\n",
      "\n",
      "ResNet Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 277.97s, Loss: 0.0295, Macro F1: 0.6061, Val Loss: 0.2140, Val Macro F1: 0.3348\n",
      "\n",
      "ResNet Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 281.30s, Loss: 0.0263, Macro F1: 0.6170, Val Loss: 0.2223, Val Macro F1: 0.3100\n",
      "\n",
      "ResNet Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 281.58s, Loss: 0.0285, Macro F1: 0.6191, Val Loss: 0.2552, Val Macro F1: 0.3060\n",
      "\n",
      "ResNet Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 282.07s, Loss: 0.0236, Macro F1: 0.6303, Val Loss: 0.2271, Val Macro F1: 0.3129\n",
      "\n",
      "ResNet Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 280.43s, Loss: 0.0220, Macro F1: 0.6428, Val Loss: 0.2589, Val Macro F1: 0.3120\n",
      "\n",
      "ResNet Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 274.95s, Loss: 0.0204, Macro F1: 0.6482, Val Loss: 0.2492, Val Macro F1: 0.3086\n",
      "\n",
      "ResNet Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 282.40s, Loss: 0.0165, Macro F1: 0.6526, Val Loss: 0.2838, Val Macro F1: 0.2924\n",
      "\n",
      "ResNet Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 281.15s, Loss: 0.0161, Macro F1: 0.6581, Val Loss: 0.2404, Val Macro F1: 0.3147\n",
      "\n",
      "ResNet Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 278.10s, Loss: 0.0168, Macro F1: 0.6604, Val Loss: 0.2666, Val Macro F1: 0.2995\n",
      "\n",
      "ResNet Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 283.67s, Loss: 0.0121, Macro F1: 0.6645, Val Loss: 0.2697, Val Macro F1: 0.3116\n",
      "\n",
      "ResNet Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 284.99s, Loss: 0.0139, Macro F1: 0.6699, Val Loss: 0.2679, Val Macro F1: 0.3224\n",
      "\n",
      "ResNet Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 283.47s, Loss: 0.0129, Macro F1: 0.6671, Val Loss: 0.2934, Val Macro F1: 0.3125\n",
      "\n",
      "ResNet Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 282.18s, Loss: 0.0138, Macro F1: 0.6695, Val Loss: 0.2792, Val Macro F1: 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1.0  # Adjust as needed\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nResNet Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = resnet_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_resnet.penalty(resnet_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        grads = tape.gradient(total_loss, resnet_sub_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, resnet_sub_model.trainable_variables))\n",
    "        si_resnet.accumulate_importance(resnet_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = resnet_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "# After training, update omega\n",
    "si_resnet.update_omega()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modify_model_for_subdiagnostic_vit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vit_sub_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodify_model_for_subdiagnostic_vit\u001b[49m(vit_super_model, num_classes_sub)\n\u001b[1;32m      2\u001b[0m exclude_params_vit \u001b[38;5;241m=\u001b[39m [w\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m vit_sub_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtrainable_weights]\n\u001b[1;32m      3\u001b[0m si_vit \u001b[38;5;241m=\u001b[39m SI(vit_sub_model, exclude_params\u001b[38;5;241m=\u001b[39mexclude_params_vit)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modify_model_for_subdiagnostic_vit' is not defined"
     ]
    }
   ],
   "source": [
    "vit_sub_model = modify_model_for_subdiagnostic_vit(vit_super_model, num_classes_sub)\n",
    "exclude_params_vit = [w.name for w in vit_sub_model.layers[-1].trainable_weights]\n",
    "si_vit = SI(vit_sub_model, exclude_params=exclude_params_vit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ViT Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Time: 302.39s, Loss: nan, Macro F1: 0.0103, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25, Time: 302.16s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/25, Time: 299.35s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 4/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25, Time: 301.37s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25, Time: 302.89s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 6/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25, Time: 305.56s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25, Time: 304.95s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 8/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/25, Time: 303.86s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/25, Time: 301.60s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 10/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25, Time: 307.68s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25, Time: 304.45s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 12/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/25, Time: 302.50s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/25, Time: 299.03s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 14/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/25, Time: 305.64s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25, Time: 306.61s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 16/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/25, Time: 308.15s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/25, Time: 302.83s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 18/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25, Time: 305.75s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/25, Time: 301.05s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 20/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/25, Time: 304.84s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/25, Time: 299.17s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 22/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/25, Time: 309.30s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/25, Time: 308.20s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 24/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25, Time: 302.33s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n",
      "\n",
      "ViT Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25, Time: 306.48s, Loss: nan, Macro F1: 0.0000, Val Loss: nan, Val Macro F1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "lambda_si = 1.0  # Adjust as needed\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_macro_f1 = tf.keras.metrics.Mean(name='train_macro_f1')\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "val_macro_f1 = tf.keras.metrics.Mean(name='val_macro_f1')\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(f'\\nViT Epoch {epoch+1}/{epochs}')\n",
    "    train_macro_f1.reset_state()\n",
    "    train_loss.reset_state()\n",
    "\n",
    "    num_batches = len(X_train) // batch_size\n",
    "    progress_bar = tqdm(range(num_batches), desc='Training', leave=False)\n",
    "\n",
    "    for step in progress_bar:\n",
    "        X_batch = X_train[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_train_sub[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = vit_sub_model(X_batch, training=True)\n",
    "            task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "            si_penalty = si_vit.penalty(vit_sub_model)\n",
    "            total_loss = task_loss + (lambda_si / 2) * si_penalty\n",
    "\n",
    "        grads = tape.gradient(total_loss, vit_sub_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, vit_sub_model.trainable_variables))\n",
    "        si_vit.accumulate_importance(vit_sub_model, grads)\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        train_macro_f1.update_state(batch_macro_f1)\n",
    "        train_loss.update_state(total_loss)\n",
    "\n",
    "        progress_bar.set_postfix({'loss': train_loss.result().numpy(), 'macro_f1': train_macro_f1.result().numpy()})\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Validation\n",
    "    val_macro_f1.reset_state()\n",
    "    val_loss.reset_state()\n",
    "    val_batches = len(X_val) // batch_size\n",
    "    val_progress_bar = tqdm(range(val_batches), desc='Validation', leave=False)\n",
    "    for step in val_progress_bar:\n",
    "        X_batch = X_val[step*batch_size:(step+1)*batch_size]\n",
    "        y_batch = y_val_sub[step*batch_size:(step+1)*batch_size]\n",
    "        preds = vit_sub_model(X_batch, training=False)\n",
    "        task_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_batch, preds))\n",
    "        total_loss = task_loss\n",
    "\n",
    "        batch_macro_f1 = macro_f1(y_batch, preds)\n",
    "        val_macro_f1.update_state(batch_macro_f1)\n",
    "        val_loss.update_state(total_loss)\n",
    "\n",
    "        val_progress_bar.set_postfix({'val_loss': val_loss.result().numpy(), 'val_macro_f1': val_macro_f1.result().numpy()})\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, '\n",
    "          f'Time: {epoch_time:.2f}s, '\n",
    "          f'Loss: {train_loss.result():.4f}, '\n",
    "          f'Macro F1: {train_macro_f1.result():.4f}, '\n",
    "          f'Val Loss: {val_loss.result():.4f}, '\n",
    "          f'Val Macro F1: {val_macro_f1.result():.4f}')\n",
    "\n",
    "# After training, update omega\n",
    "si_vit.update_omega()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling and Publishing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.71      0.74      0.73       306\n",
      "       CLBBB       0.93      0.78      0.85        54\n",
      "       CRBBB       0.76      0.89      0.82        54\n",
      "       ILBBB       0.25      0.12      0.17         8\n",
      "         IMI       0.66      0.57      0.61       327\n",
      "       IRBBB       0.72      0.44      0.54       112\n",
      "        ISCA       0.44      0.31      0.36        93\n",
      "        ISCI       0.67      0.10      0.17        40\n",
      "        ISC_       0.67      0.55      0.61       128\n",
      "        IVCD       0.19      0.10      0.13        79\n",
      "   LAFB/LPFB       0.78      0.54      0.64       179\n",
      "     LAO/LAE       0.29      0.05      0.08        42\n",
      "         LMI       0.14      0.05      0.07        20\n",
      "         LVH       0.72      0.51      0.60       214\n",
      "        NORM       0.82      0.88      0.85       963\n",
      "        NST_       0.17      0.05      0.08        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       1.00      0.20      0.33        10\n",
      "         RVH       0.33      0.17      0.22        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.42      0.54      0.47       222\n",
      "         WPW       1.00      0.25      0.40         8\n",
      "        _AVB       0.47      0.22      0.30        82\n",
      "\n",
      "   micro avg       0.70      0.62      0.66      3034\n",
      "   macro avg       0.53      0.35      0.39      3034\n",
      "weighted avg       0.67      0.62      0.63      3034\n",
      " samples avg       0.68      0.66      0.65      3034\n",
      "\n",
      "CNN EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.72      0.51      0.60       496\n",
      "         HYP       0.75      0.28      0.41       262\n",
      "          MI       0.86      0.43      0.57       550\n",
      "        NORM       0.89      0.25      0.39       963\n",
      "        STTC       0.84      0.35      0.50       521\n",
      "\n",
      "   micro avg       0.81      0.35      0.49      2792\n",
      "   macro avg       0.81      0.36      0.49      2792\n",
      "weighted avg       0.83      0.35      0.49      2792\n",
      " samples avg       0.39      0.34      0.35      2792\n",
      "\n",
      "ResNet EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.69      0.73      0.71       306\n",
      "       CLBBB       0.95      0.76      0.85        54\n",
      "       CRBBB       0.79      0.96      0.87        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.54      0.75      0.63       327\n",
      "       IRBBB       0.60      0.45      0.51       112\n",
      "        ISCA       0.28      0.46      0.35        93\n",
      "        ISCI       0.53      0.23      0.32        40\n",
      "        ISC_       0.60      0.52      0.56       128\n",
      "        IVCD       0.15      0.08      0.10        79\n",
      "   LAFB/LPFB       0.69      0.69      0.69       179\n",
      "     LAO/LAE       0.36      0.10      0.15        42\n",
      "         LMI       0.23      0.15      0.18        20\n",
      "         LVH       0.68      0.49      0.57       214\n",
      "        NORM       0.82      0.80      0.81       963\n",
      "        NST_       0.23      0.10      0.14        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.67      0.20      0.31        10\n",
      "         RVH       0.25      0.08      0.12        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.45      0.34      0.39       222\n",
      "         WPW       0.67      0.50      0.57         8\n",
      "        _AVB       0.50      0.29      0.37        82\n",
      "\n",
      "   micro avg       0.65      0.61      0.63      3034\n",
      "   macro avg       0.46      0.38      0.40      3034\n",
      "weighted avg       0.64      0.61      0.62      3034\n",
      " samples avg       0.64      0.64      0.62      3034\n",
      "\n",
      "ResNet EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.78      0.24      0.37       496\n",
      "         HYP       0.66      0.30      0.41       262\n",
      "          MI       0.69      0.65      0.67       550\n",
      "        NORM       0.89      0.47      0.62       963\n",
      "        STTC       0.60      0.18      0.28       521\n",
      "\n",
      "   micro avg       0.76      0.40      0.52      2792\n",
      "   macro avg       0.72      0.37      0.47      2792\n",
      "weighted avg       0.76      0.40      0.50      2792\n",
      " samples avg       0.46      0.41      0.42      2792\n",
      "\n",
      "ViT EWC Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.00      0.00      0.00       306\n",
      "       CLBBB       0.00      0.00      0.00        54\n",
      "       CRBBB       0.00      0.00      0.00        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.00      0.00      0.00       327\n",
      "       IRBBB       0.00      0.00      0.00       112\n",
      "        ISCA       0.00      0.00      0.00        93\n",
      "        ISCI       0.00      0.00      0.00        40\n",
      "        ISC_       0.00      0.00      0.00       128\n",
      "        IVCD       0.00      0.00      0.00        79\n",
      "   LAFB/LPFB       0.00      0.00      0.00       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.00      0.00      0.00        20\n",
      "         LVH       0.00      0.00      0.00       214\n",
      "        NORM       0.00      0.00      0.00       963\n",
      "        NST_       0.00      0.00      0.00        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.00      0.00      0.00        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.00      0.00      0.00       222\n",
      "         WPW       0.00      0.00      0.00         8\n",
      "        _AVB       0.00      0.00      0.00        82\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      3034\n",
      "   macro avg       0.00      0.00      0.00      3034\n",
      "weighted avg       0.00      0.00      0.00      3034\n",
      " samples avg       0.00      0.00      0.00      3034\n",
      "\n",
      "ViT EWC Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.00      0.00      0.00       496\n",
      "         HYP       0.00      0.00      0.00       262\n",
      "          MI       0.00      0.00      0.00       550\n",
      "        NORM       0.00      0.00      0.00       963\n",
      "        STTC       0.00      0.00      0.00       521\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      2792\n",
      "   macro avg       0.00      0.00      0.00      2792\n",
      "weighted avg       0.00      0.00      0.00      2792\n",
      " samples avg       0.00      0.00      0.00      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN EWC Subdiagnostic Classification Report:\")\n",
    "cnn_ewc_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"CNN EWC Superdiagnostic Classification Report:\")\n",
    "cnn_ewc_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet EWC Subdiagnostic Classification Report:\")\n",
    "resnet_ewc_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet EWC Superdiagnostic Classification Report:\")\n",
    "resnet_ewc_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT EWC Subdiagnostic Classification Report:\")\n",
    "vit_ewc_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT EWC Superdiagnostic Classification Report:\")\n",
    "vit_ewc_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.71      0.74      0.73       306\n",
      "       CLBBB       0.93      0.78      0.85        54\n",
      "       CRBBB       0.76      0.89      0.82        54\n",
      "       ILBBB       0.25      0.12      0.17         8\n",
      "         IMI       0.66      0.57      0.61       327\n",
      "       IRBBB       0.72      0.44      0.54       112\n",
      "        ISCA       0.44      0.31      0.36        93\n",
      "        ISCI       0.67      0.10      0.17        40\n",
      "        ISC_       0.67      0.55      0.61       128\n",
      "        IVCD       0.19      0.10      0.13        79\n",
      "   LAFB/LPFB       0.78      0.54      0.64       179\n",
      "     LAO/LAE       0.29      0.05      0.08        42\n",
      "         LMI       0.14      0.05      0.07        20\n",
      "         LVH       0.72      0.51      0.60       214\n",
      "        NORM       0.82      0.88      0.85       963\n",
      "        NST_       0.17      0.05      0.08        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       1.00      0.20      0.33        10\n",
      "         RVH       0.33      0.17      0.22        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.42      0.54      0.47       222\n",
      "         WPW       1.00      0.25      0.40         8\n",
      "        _AVB       0.47      0.22      0.30        82\n",
      "\n",
      "   micro avg       0.70      0.62      0.66      3034\n",
      "   macro avg       0.53      0.35      0.39      3034\n",
      "weighted avg       0.67      0.62      0.63      3034\n",
      " samples avg       0.68      0.66      0.65      3034\n",
      "\n",
      "CNN SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.72      0.51      0.60       496\n",
      "         HYP       0.75      0.28      0.41       262\n",
      "          MI       0.86      0.43      0.57       550\n",
      "        NORM       0.89      0.25      0.39       963\n",
      "        STTC       0.84      0.35      0.50       521\n",
      "\n",
      "   micro avg       0.81      0.35      0.49      2792\n",
      "   macro avg       0.81      0.36      0.49      2792\n",
      "weighted avg       0.83      0.35      0.49      2792\n",
      " samples avg       0.39      0.34      0.35      2792\n",
      "\n",
      "ResNet SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.69      0.73      0.71       306\n",
      "       CLBBB       0.95      0.76      0.85        54\n",
      "       CRBBB       0.79      0.96      0.87        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.54      0.75      0.63       327\n",
      "       IRBBB       0.60      0.45      0.51       112\n",
      "        ISCA       0.28      0.46      0.35        93\n",
      "        ISCI       0.53      0.23      0.32        40\n",
      "        ISC_       0.60      0.52      0.56       128\n",
      "        IVCD       0.15      0.08      0.10        79\n",
      "   LAFB/LPFB       0.69      0.69      0.69       179\n",
      "     LAO/LAE       0.36      0.10      0.15        42\n",
      "         LMI       0.23      0.15      0.18        20\n",
      "         LVH       0.68      0.49      0.57       214\n",
      "        NORM       0.82      0.80      0.81       963\n",
      "        NST_       0.23      0.10      0.14        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.67      0.20      0.31        10\n",
      "         RVH       0.25      0.08      0.12        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.45      0.34      0.39       222\n",
      "         WPW       0.67      0.50      0.57         8\n",
      "        _AVB       0.50      0.29      0.37        82\n",
      "\n",
      "   micro avg       0.65      0.61      0.63      3034\n",
      "   macro avg       0.46      0.38      0.40      3034\n",
      "weighted avg       0.64      0.61      0.62      3034\n",
      " samples avg       0.64      0.64      0.62      3034\n",
      "\n",
      "ResNet SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.78      0.24      0.37       496\n",
      "         HYP       0.66      0.30      0.41       262\n",
      "          MI       0.69      0.65      0.67       550\n",
      "        NORM       0.89      0.47      0.62       963\n",
      "        STTC       0.60      0.18      0.28       521\n",
      "\n",
      "   micro avg       0.76      0.40      0.52      2792\n",
      "   macro avg       0.72      0.37      0.47      2792\n",
      "weighted avg       0.76      0.40      0.50      2792\n",
      " samples avg       0.46      0.41      0.42      2792\n",
      "\n",
      "ViT SI Subdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AMI       0.00      0.00      0.00       306\n",
      "       CLBBB       0.00      0.00      0.00        54\n",
      "       CRBBB       0.00      0.00      0.00        54\n",
      "       ILBBB       0.00      0.00      0.00         8\n",
      "         IMI       0.00      0.00      0.00       327\n",
      "       IRBBB       0.00      0.00      0.00       112\n",
      "        ISCA       0.00      0.00      0.00        93\n",
      "        ISCI       0.00      0.00      0.00        40\n",
      "        ISC_       0.00      0.00      0.00       128\n",
      "        IVCD       0.00      0.00      0.00        79\n",
      "   LAFB/LPFB       0.00      0.00      0.00       179\n",
      "     LAO/LAE       0.00      0.00      0.00        42\n",
      "         LMI       0.00      0.00      0.00        20\n",
      "         LVH       0.00      0.00      0.00       214\n",
      "        NORM       0.00      0.00      0.00       963\n",
      "        NST_       0.00      0.00      0.00        77\n",
      "         PMI       0.00      0.00      0.00         2\n",
      "     RAO/RAE       0.00      0.00      0.00        10\n",
      "         RVH       0.00      0.00      0.00        12\n",
      "       SEHYP       0.00      0.00      0.00         2\n",
      "        STTC       0.00      0.00      0.00       222\n",
      "         WPW       0.00      0.00      0.00         8\n",
      "        _AVB       0.00      0.00      0.00        82\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      3034\n",
      "   macro avg       0.00      0.00      0.00      3034\n",
      "weighted avg       0.00      0.00      0.00      3034\n",
      " samples avg       0.00      0.00      0.00      3034\n",
      "\n",
      "ViT SI Superdiagnostic Classification Report:\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CD       0.00      0.00      0.00       496\n",
      "         HYP       0.00      0.00      0.00       262\n",
      "          MI       0.00      0.00      0.00       550\n",
      "        NORM       0.00      0.00      0.00       963\n",
      "        STTC       0.00      0.00      0.00       521\n",
      "\n",
      "   micro avg       0.00      0.00      0.00      2792\n",
      "   macro avg       0.00      0.00      0.00      2792\n",
      "weighted avg       0.00      0.00      0.00      2792\n",
      " samples avg       0.00      0.00      0.00      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CNN SI Subdiagnostic Classification Report:\")\n",
    "cnn_si_sub_report = evaluate_model(cnn_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"CNN SI Superdiagnostic Classification Report:\")\n",
    "cnn_si_super_report = evaluate_model(cnn_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ResNet SI Subdiagnostic Classification Report:\")\n",
    "resnet_si_sub_report = evaluate_model(resnet_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ResNet SI Superdiagnostic Classification Report:\")\n",
    "resnet_si_super_report = evaluate_model(resnet_super_model, X_test, y_test_super, classes_super)\n",
    "\n",
    "print(\"ViT SI Subdiagnostic Classification Report:\")\n",
    "vit_si_sub_report = evaluate_model(vit_sub_model, X_test, y_test_sub, classes_sub)\n",
    "\n",
    "print(\"ViT SI Superdiagnostic Classification Report:\")\n",
    "vit_si_super_report = evaluate_model(vit_super_model, X_test, y_test_super, classes_super)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Classification Performance:\n",
      "     Model                 Task  Macro F1-score\n",
      "0      CNN      Superdiagnostic        0.734213\n",
      "1   ResNet      Superdiagnostic        0.732228\n",
      "2      ViT      Superdiagnostic        0.679261\n",
      "3      CNN        Subdiagnostic        0.408998\n",
      "4   ResNet        Subdiagnostic        0.392051\n",
      "5      ViT        Subdiagnostic        0.275582\n",
      "6      CNN    EWC Subdiagnostic        0.393380\n",
      "7   ResNet    EWC Subdiagnostic        0.399722\n",
      "8      ViT    EWC Subdiagnostic        0.000000\n",
      "9      CNN  EWC Superdiagnostic        0.493559\n",
      "10  ResNet  EWC Superdiagnostic        0.469332\n",
      "11     ViT  EWC Superdiagnostic        0.000000\n",
      "12     CNN     SI Subdiagnostic        0.393380\n",
      "13  ResNet     SI Subdiagnostic        0.399722\n",
      "14     ViT     SI Subdiagnostic        0.000000\n",
      "15     CNN   SI Superdiagnostic        0.493559\n",
      "16  ResNet   SI Superdiagnostic        0.469332\n",
      "17     ViT   SI Superdiagnostic        0.000000\n"
     ]
    }
   ],
   "source": [
    "def get_macro_f1(report_dict):\n",
    "    return report_dict['macro avg']['f1-score']\n",
    "\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Task': [],\n",
    "    'Macro F1-score': []\n",
    "}\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_super_report),\n",
    "    get_macro_f1(resnet_super_report),\n",
    "    get_macro_f1(vit_super_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_sub_report),\n",
    "    get_macro_f1(resnet_sub_report),\n",
    "    get_macro_f1(vit_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['EWC Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_ewc_sub_report),\n",
    "    get_macro_f1(resnet_ewc_sub_report),\n",
    "    get_macro_f1(vit_ewc_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['EWC Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_ewc_super_report),\n",
    "    get_macro_f1(resnet_ewc_super_report),\n",
    "    get_macro_f1(vit_ewc_super_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['SI Subdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_si_sub_report),\n",
    "    get_macro_f1(resnet_si_sub_report),\n",
    "    get_macro_f1(vit_si_sub_report)\n",
    "])\n",
    "\n",
    "results['Model'].extend(['CNN', 'ResNet', 'ViT'])\n",
    "results['Task'].extend(['SI Superdiagnostic'] * 3)\n",
    "results['Macro F1-score'].extend([\n",
    "    get_macro_f1(cnn_si_super_report),\n",
    "    get_macro_f1(resnet_si_super_report),\n",
    "    get_macro_f1(vit_si_super_report)\n",
    "])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Classification Performance:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
